{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_a9Z_tMwn87"
      },
      "source": [
        "```\n",
        "CEPARCO-S11\n",
        "GROUP 2\n",
        "TOPIC: GPU-CPU Memory Transfer\n",
        "MEMBERS:\n",
        "    ALONZO, Jose Anton S.\n",
        "    AVELINO, Joris Gabriel L.\n",
        "    CRUZ, Airon John R.\n",
        "    HERNANDEZ, Pierre Vincent C.\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONKwaRAQxlBM"
      },
      "source": [
        "#IMPLEMENTATION #1: Old Method or Transferring data between CPU and Memory (memCUDA copy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector Size: `2^20`"
      ],
      "metadata": {
        "id": "6DHuECUWXUyV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of Threads: `256`"
      ],
      "metadata": {
        "id": "KM5QbO-yXmfc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qs02pyKZxrrX"
      },
      "outputs": [],
      "source": [
        "%%writefile CUDA_1_256_20.cu\n",
        "\n",
        "#include<stdio.h>\n",
        "#include<stdlib.h>\n",
        "\n",
        "__global__ \n",
        "void convolution(float* in, float* out, int size)\n",
        "{\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < size - 2; i += stride) {\n",
        "    out[i] = (in[i] + in[i+1] + in[i+2]) / 3.0f;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main ()\n",
        "{\n",
        "\n",
        "  // Initialization of constant variables\n",
        "  const int VECTOR_SIZE = 1 << 20; // Modify depending on the needed value\n",
        "  const int VECTOR_BYTES = VECTOR_SIZE * sizeof(float);\n",
        "  const int THREAD_NUM = 256; // Modify depending on the needed value\n",
        "  const int RUN_CNT = 30; // Modify depending on the needed value \n",
        "\n",
        "  int numBlocks = (VECTOR_SIZE + THREAD_NUM - 1) / THREAD_NUM; // Initialize number of blocks\n",
        "\n",
        "  // Declaration of I/O variables\n",
        "  float* h_in;\n",
        "  float* h_out; // Host (i.e. CPU) variables\n",
        "  float* d_in;\n",
        "  float* d_out; // Device (i.e. GPU) variables\n",
        "  \n",
        "  // Print current specifications\n",
        "  printf(\"\\n%s\\n%s: %d\\n%s: %d\\n%s: %d\\n\\n\",\n",
        "  \"-- 1-D Convolution --\",\n",
        "  \"Vector size\", VECTOR_SIZE,\n",
        "  \"Number of threads\", THREAD_NUM,\n",
        "  \"Number of blocks\", numBlocks\n",
        "  );\n",
        "\n",
        "  // STEP 1: Allocate HOST memory\n",
        "\n",
        "  h_in = (float*)malloc(VECTOR_BYTES);\n",
        "  h_out = (float*)malloc(VECTOR_BYTES);\n",
        "\n",
        "  // Initialization of data\n",
        "\n",
        "  for (int i = 0; i < VECTOR_SIZE; i++){\n",
        "    h_in[i] = float(i);\n",
        "  }\n",
        "\n",
        "  // STEP 2: Allocate DEVICE memory \n",
        "\n",
        "  cudaMalloc((void**)&d_in, VECTOR_BYTES);\n",
        "  cudaMalloc((void**)&d_out, VECTOR_BYTES);\n",
        "\n",
        "  // STEP 3: Transfer data from host to device memory\n",
        "\n",
        "  cudaMemcpy(d_in, h_in, VECTOR_BYTES, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_out, h_out, VECTOR_BYTES, cudaMemcpyHostToDevice);\n",
        "\n",
        "  // STEP 4: Execute (convolution) kernel\n",
        "\n",
        "  for (int j = 0; j < RUN_CNT; j++)\n",
        "    convolution<<<numBlocks, THREAD_NUM>>>(d_in, d_out, VECTOR_SIZE);\n",
        "\n",
        "  // STEP 5: Transfer data back to host memory\n",
        "\n",
        "  cudaMemcpy(h_out, d_out, VECTOR_BYTES, cudaMemcpyDeviceToHost);\n",
        "\n",
        "  // Error Checking\n",
        "  int errorCount = 0;\n",
        "  for(int k = 0; k < VECTOR_SIZE - 2; k++) \n",
        "  {\n",
        "    if ( (h_in[k] + h_in[k+1] + h_in[k+2]) / 3.0f != h_out[k])\n",
        "      errorCount++;\n",
        "  }\n",
        "\n",
        "  printf(\"Error count: %d\\n\", errorCount);\n",
        "\n",
        "  // STEP 6: Deallocate HOST memory\n",
        "\n",
        "  free(h_in);\n",
        "  free(h_out);\n",
        "  \n",
        "  // STEP 7: Deallocate DEVICE memory\n",
        "\n",
        "  cudaFree(d_in);\n",
        "  cudaFree(d_out);\n",
        "\n",
        "  return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc CUDA_1_256_20.cu -o CUDA_1_256_20\n",
        "nvprof ./CUDA_1_256_20"
      ],
      "metadata": {
        "id": "LvfOwKgdHumJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of Threads: `512`"
      ],
      "metadata": {
        "id": "P1pZoCvYYAnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile CUDA_1_512_20.cu\n",
        "\n",
        "#include<stdio.h>\n",
        "#include<stdlib.h>\n",
        "\n",
        "__global__ \n",
        "void convolution(float* in, float* out, int size)\n",
        "{\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < size - 2; i += stride) {\n",
        "    out[i] = (in[i] + in[i+1] + in[i+2]) / 3.0f;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main ()\n",
        "{\n",
        "\n",
        "  // Initialization of constant variables\n",
        "  const int VECTOR_SIZE = 1 << 20; // Modify depending on the needed value\n",
        "  const int VECTOR_BYTES = VECTOR_SIZE * sizeof(float);\n",
        "  const int THREAD_NUM = 512; // Modify depending on the needed value\n",
        "  const int RUN_CNT = 30; // Modify depending on the needed value \n",
        "\n",
        "  int numBlocks = (VECTOR_SIZE + THREAD_NUM - 1) / THREAD_NUM; // Initialize number of blocks\n",
        "\n",
        "  // Declaration of I/O variables\n",
        "  float* h_in;\n",
        "  float* h_out; // Host (i.e. CPU) variables\n",
        "  float* d_in;\n",
        "  float* d_out; // Device (i.e. GPU) variables\n",
        "  \n",
        "  // Print current specifications\n",
        "  printf(\"\\n%s\\n%s: %d\\n%s: %d\\n%s: %d\\n\\n\",\n",
        "  \"-- 1-D Convolution --\",\n",
        "  \"Vector size\", VECTOR_SIZE,\n",
        "  \"Number of threads\", THREAD_NUM,\n",
        "  \"Number of blocks\", numBlocks\n",
        "  );\n",
        "\n",
        "  // STEP 1: Allocate HOST memory\n",
        "\n",
        "  h_in = (float*)malloc(VECTOR_BYTES);\n",
        "  h_out = (float*)malloc(VECTOR_BYTES);\n",
        "\n",
        "  // Initialization of data\n",
        "\n",
        "  for (int i = 0; i < VECTOR_SIZE; i++){\n",
        "    h_in[i] = float(i);\n",
        "  }\n",
        "\n",
        "  // STEP 2: Allocate DEVICE memory \n",
        "\n",
        "  cudaMalloc((void**)&d_in, VECTOR_BYTES);\n",
        "  cudaMalloc((void**)&d_out, VECTOR_BYTES);\n",
        "\n",
        "  // STEP 3: Transfer data from host to device memory\n",
        "\n",
        "  cudaMemcpy(d_in, h_in, VECTOR_BYTES, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_out, h_out, VECTOR_BYTES, cudaMemcpyHostToDevice);\n",
        "\n",
        "  // STEP 4: Execute (convolution) kernel\n",
        "\n",
        "  for (int j = 0; j < RUN_CNT; j++)\n",
        "    convolution<<<numBlocks, THREAD_NUM>>>(d_in, d_out, VECTOR_SIZE);\n",
        "\n",
        "  // STEP 5: Transfer data back to host memory\n",
        "\n",
        "  cudaMemcpy(h_out, d_out, VECTOR_BYTES, cudaMemcpyDeviceToHost);\n",
        "\n",
        "  // Error Checking\n",
        "  int errorCount = 0;\n",
        "  for(int k = 0; k < VECTOR_SIZE - 2; k++) \n",
        "  {\n",
        "    if ( (h_in[k] + h_in[k+1] + h_in[k+2]) / 3.0f != h_out[k])\n",
        "      errorCount++;\n",
        "  }\n",
        "\n",
        "  printf(\"Error count: %d\\n\", errorCount);\n",
        "\n",
        "  // STEP 6: Deallocate HOST memory\n",
        "\n",
        "  free(h_in);\n",
        "  free(h_out);\n",
        "  \n",
        "  // STEP 7: Deallocate DEVICE memory\n",
        "\n",
        "  cudaFree(d_in);\n",
        "  cudaFree(d_out);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "IxP-o7OLYOxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc CUDA_1_512_20.cu -o CUDA_1_512_20\n",
        "nvprof ./CUDA_1_512_20"
      ],
      "metadata": {
        "id": "5UTZcWs5MF1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of Threads: `1024`"
      ],
      "metadata": {
        "id": "Z2xvE2wcYJxT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile CUDA_1_1K_20.cu\n",
        "\n",
        "#include<stdio.h>\n",
        "#include<stdlib.h>\n",
        "\n",
        "__global__ \n",
        "void convolution(float* in, float* out, int size)\n",
        "{\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < size - 2; i += stride) {\n",
        "    out[i] = (in[i] + in[i+1] + in[i+2]) / 3.0f;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main ()\n",
        "{\n",
        "\n",
        "  // Initialization of constant variables\n",
        "  const int VECTOR_SIZE = 1 << 20; // Modify depending on the needed value\n",
        "  const int VECTOR_BYTES = VECTOR_SIZE * sizeof(float);\n",
        "  const int THREAD_NUM = 1024; // Modify depending on the needed value\n",
        "  const int RUN_CNT = 30; // Modify depending on the needed value \n",
        "\n",
        "  int numBlocks = (VECTOR_SIZE + THREAD_NUM - 1) / THREAD_NUM; // Initialize number of blocks\n",
        "\n",
        "  // Declaration of I/O variables\n",
        "  float* h_in;\n",
        "  float* h_out; // Host (i.e. CPU) variables\n",
        "  float* d_in;\n",
        "  float* d_out; // Device (i.e. GPU) variables\n",
        "  \n",
        "  // Print current specifications\n",
        "  printf(\"\\n%s\\n%s: %d\\n%s: %d\\n%s: %d\\n\\n\",\n",
        "  \"-- 1-D Convolution --\",\n",
        "  \"Vector size\", VECTOR_SIZE,\n",
        "  \"Number of threads\", THREAD_NUM,\n",
        "  \"Number of blocks\", numBlocks\n",
        "  );\n",
        "\n",
        "  // STEP 1: Allocate HOST memory\n",
        "\n",
        "  h_in = (float*)malloc(VECTOR_BYTES);\n",
        "  h_out = (float*)malloc(VECTOR_BYTES);\n",
        "\n",
        "  // Initialization of data\n",
        "\n",
        "  for (int i = 0; i < VECTOR_SIZE; i++){\n",
        "    h_in[i] = float(i);\n",
        "  }\n",
        "\n",
        "  // STEP 2: Allocate DEVICE memory \n",
        "\n",
        "  cudaMalloc((void**)&d_in, VECTOR_BYTES);\n",
        "  cudaMalloc((void**)&d_out, VECTOR_BYTES);\n",
        "\n",
        "  // STEP 3: Transfer data from host to device memory\n",
        "\n",
        "  cudaMemcpy(d_in, h_in, VECTOR_BYTES, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_out, h_out, VECTOR_BYTES, cudaMemcpyHostToDevice);\n",
        "\n",
        "  // STEP 4: Execute (convolution) kernel\n",
        "\n",
        "  for (int j = 0; j < RUN_CNT; j++)\n",
        "    convolution<<<numBlocks, THREAD_NUM>>>(d_in, d_out, VECTOR_SIZE);\n",
        "\n",
        "  // STEP 5: Transfer data back to host memory\n",
        "\n",
        "  cudaMemcpy(h_out, d_out, VECTOR_BYTES, cudaMemcpyDeviceToHost);\n",
        "\n",
        "  // Error Checking\n",
        "  int errorCount = 0;\n",
        "  for(int k = 0; k < VECTOR_SIZE - 2; k++) \n",
        "  {\n",
        "    if ( (h_in[k] + h_in[k+1] + h_in[k+2]) / 3.0f != h_out[k])\n",
        "      errorCount++;\n",
        "  }\n",
        "\n",
        "  printf(\"Error count: %d\\n\", errorCount);\n",
        "\n",
        "  // STEP 6: Deallocate HOST memory\n",
        "\n",
        "  free(h_in);\n",
        "  free(h_out);\n",
        "  \n",
        "  // STEP 7: Deallocate DEVICE memory\n",
        "\n",
        "  cudaFree(d_in);\n",
        "  cudaFree(d_out);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "DP_nFGdtYSFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc CUDA_1_1K_20.cu -o CUDA_1_1K_20\n",
        "nvprof ./CUDA_1_1K_20"
      ],
      "metadata": {
        "id": "LNI16h3MMPA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector Size: `2^22`"
      ],
      "metadata": {
        "id": "5oAJHZXoYYIj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of Threads: `256`"
      ],
      "metadata": {
        "id": "8VABUz_PYYIj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRT_81JkYYIk"
      },
      "outputs": [],
      "source": [
        "%%writefile CUDA_1_256_22.cu\n",
        "\n",
        "#include<stdio.h>\n",
        "#include<stdlib.h>\n",
        "\n",
        "__global__ \n",
        "void convolution(float* in, float* out, int size)\n",
        "{\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < size - 2; i += stride) {\n",
        "    out[i] = (in[i] + in[i+1] + in[i+2]) / 3.0f;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main ()\n",
        "{\n",
        "\n",
        "  // Initialization of constant variables\n",
        "  const int VECTOR_SIZE = 1 << 22; // Modify depending on the needed value\n",
        "  const int VECTOR_BYTES = VECTOR_SIZE * sizeof(float);\n",
        "  const int THREAD_NUM = 256; // Modify depending on the needed value\n",
        "  const int RUN_CNT = 30; // Modify depending on the needed value \n",
        "\n",
        "  int numBlocks = (VECTOR_SIZE + THREAD_NUM - 1) / THREAD_NUM; // Initialize number of blocks\n",
        "\n",
        "  // Declaration of I/O variables\n",
        "  float* h_in;\n",
        "  float* h_out; // Host (i.e. CPU) variables\n",
        "  float* d_in;\n",
        "  float* d_out; // Device (i.e. GPU) variables\n",
        "  \n",
        "  // Print current specifications\n",
        "  printf(\"\\n%s\\n%s: %d\\n%s: %d\\n%s: %d\\n\\n\",\n",
        "  \"-- 1-D Convolution --\",\n",
        "  \"Vector size\", VECTOR_SIZE,\n",
        "  \"Number of threads\", THREAD_NUM,\n",
        "  \"Number of blocks\", numBlocks\n",
        "  );\n",
        "\n",
        "  // STEP 1: Allocate HOST memory\n",
        "\n",
        "  h_in = (float*)malloc(VECTOR_BYTES);\n",
        "  h_out = (float*)malloc(VECTOR_BYTES);\n",
        "\n",
        "  // Initialization of data\n",
        "\n",
        "  for (int i = 0; i < VECTOR_SIZE; i++){\n",
        "    h_in[i] = float(i);\n",
        "  }\n",
        "\n",
        "  // STEP 2: Allocate DEVICE memory \n",
        "\n",
        "  cudaMalloc((void**)&d_in, VECTOR_BYTES);\n",
        "  cudaMalloc((void**)&d_out, VECTOR_BYTES);\n",
        "\n",
        "  // STEP 3: Transfer data from host to device memory\n",
        "\n",
        "  cudaMemcpy(d_in, h_in, VECTOR_BYTES, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_out, h_out, VECTOR_BYTES, cudaMemcpyHostToDevice);\n",
        "\n",
        "  // STEP 4: Execute (convolution) kernel\n",
        "\n",
        "  for (int j = 0; j < RUN_CNT; j++)\n",
        "    convolution<<<numBlocks, THREAD_NUM>>>(d_in, d_out, VECTOR_SIZE);\n",
        "\n",
        "  // STEP 5: Transfer data back to host memory\n",
        "\n",
        "  cudaMemcpy(h_out, d_out, VECTOR_BYTES, cudaMemcpyDeviceToHost);\n",
        "\n",
        "  // Error Checking\n",
        "  int errorCount = 0;\n",
        "  for(int k = 0; k < VECTOR_SIZE - 2; k++) \n",
        "  {\n",
        "    if ( (h_in[k] + h_in[k+1] + h_in[k+2]) / 3.0f != h_out[k])\n",
        "      errorCount++;\n",
        "  }\n",
        "\n",
        "  printf(\"Error count: %d\\n\", errorCount);\n",
        "\n",
        "  // STEP 6: Deallocate HOST memory\n",
        "\n",
        "  free(h_in);\n",
        "  free(h_out);\n",
        "  \n",
        "  // STEP 7: Deallocate DEVICE memory\n",
        "\n",
        "  cudaFree(d_in);\n",
        "  cudaFree(d_out);\n",
        "\n",
        "  return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc CUDA_1_256_22.cu -o CUDA_1_256_22\n",
        "nvprof ./CUDA_1_256_22"
      ],
      "metadata": {
        "id": "7mEBJmhrMSSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of Threads: `512`"
      ],
      "metadata": {
        "id": "mfgKTqdGYYIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile CUDA_1_512_22.cu\n",
        "\n",
        "#include<stdio.h>\n",
        "#include<stdlib.h>\n",
        "\n",
        "__global__ \n",
        "void convolution(float* in, float* out, int size)\n",
        "{\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < size - 2; i += stride) {\n",
        "    out[i] = (in[i] + in[i+1] + in[i+2]) / 3.0f;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main ()\n",
        "{\n",
        "\n",
        "  // Initialization of constant variables\n",
        "  const int VECTOR_SIZE = 1 << 22; // Modify depending on the needed value\n",
        "  const int VECTOR_BYTES = VECTOR_SIZE * sizeof(float);\n",
        "  const int THREAD_NUM = 512; // Modify depending on the needed value\n",
        "  const int RUN_CNT = 30; // Modify depending on the needed value \n",
        "\n",
        "  int numBlocks = (VECTOR_SIZE + THREAD_NUM - 1) / THREAD_NUM; // Initialize number of blocks\n",
        "\n",
        "  // Declaration of I/O variables\n",
        "  float* h_in;\n",
        "  float* h_out; // Host (i.e. CPU) variables\n",
        "  float* d_in;\n",
        "  float* d_out; // Device (i.e. GPU) variables\n",
        "  \n",
        "  // Print current specifications\n",
        "  printf(\"\\n%s\\n%s: %d\\n%s: %d\\n%s: %d\\n\\n\",\n",
        "  \"-- 1-D Convolution --\",\n",
        "  \"Vector size\", VECTOR_SIZE,\n",
        "  \"Number of threads\", THREAD_NUM,\n",
        "  \"Number of blocks\", numBlocks\n",
        "  );\n",
        "\n",
        "  // STEP 1: Allocate HOST memory\n",
        "\n",
        "  h_in = (float*)malloc(VECTOR_BYTES);\n",
        "  h_out = (float*)malloc(VECTOR_BYTES);\n",
        "\n",
        "  // Initialization of data\n",
        "\n",
        "  for (int i = 0; i < VECTOR_SIZE; i++){\n",
        "    h_in[i] = float(i);\n",
        "  }\n",
        "\n",
        "  // STEP 2: Allocate DEVICE memory \n",
        "\n",
        "  cudaMalloc((void**)&d_in, VECTOR_BYTES);\n",
        "  cudaMalloc((void**)&d_out, VECTOR_BYTES);\n",
        "\n",
        "  // STEP 3: Transfer data from host to device memory\n",
        "\n",
        "  cudaMemcpy(d_in, h_in, VECTOR_BYTES, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_out, h_out, VECTOR_BYTES, cudaMemcpyHostToDevice);\n",
        "\n",
        "  // STEP 4: Execute (convolution) kernel\n",
        "\n",
        "  for (int j = 0; j < RUN_CNT; j++)\n",
        "    convolution<<<numBlocks, THREAD_NUM>>>(d_in, d_out, VECTOR_SIZE);\n",
        "\n",
        "  // STEP 5: Transfer data back to host memory\n",
        "\n",
        "  cudaMemcpy(h_out, d_out, VECTOR_BYTES, cudaMemcpyDeviceToHost);\n",
        "\n",
        "  // Error Checking\n",
        "  int errorCount = 0;\n",
        "  for(int k = 0; k < VECTOR_SIZE - 2; k++) \n",
        "  {\n",
        "    if ( (h_in[k] + h_in[k+1] + h_in[k+2]) / 3.0f != h_out[k])\n",
        "      errorCount++;\n",
        "  }\n",
        "\n",
        "  printf(\"Error count: %d\\n\", errorCount);\n",
        "\n",
        "  // STEP 6: Deallocate HOST memory\n",
        "\n",
        "  free(h_in);\n",
        "  free(h_out);\n",
        "  \n",
        "  // STEP 7: Deallocate DEVICE memory\n",
        "\n",
        "  cudaFree(d_in);\n",
        "  cudaFree(d_out);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "LFrSHH1qYYIk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5793fce-5340-4bd8-ec5b-c6c38bff1e0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing CUDA_1_512_22.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc CUDA_1_512_22.cu -o CUDA_1_512_20\n",
        "nvprof ./CUDA_1_512_22"
      ],
      "metadata": {
        "id": "mAjSRQSlMUu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of Threads: `1024`"
      ],
      "metadata": {
        "id": "FwJ8kIisYYIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile CUDA_1_1K_22.cu\n",
        "\n",
        "#include<stdio.h>\n",
        "#include<stdlib.h>\n",
        "\n",
        "__global__ \n",
        "void convolution(float* in, float* out, int size)\n",
        "{\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < size - 2; i += stride) {\n",
        "    out[i] = (in[i] + in[i+1] + in[i+2]) / 3.0f;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main ()\n",
        "{\n",
        "\n",
        "  // Initialization of constant variables\n",
        "  const int VECTOR_SIZE = 1 << 22; // Modify depending on the needed value\n",
        "  const int VECTOR_BYTES = VECTOR_SIZE * sizeof(float);\n",
        "  const int THREAD_NUM = 1024; // Modify depending on the needed value\n",
        "  const int RUN_CNT = 30; // Modify depending on the needed value \n",
        "\n",
        "  int numBlocks = (VECTOR_SIZE + THREAD_NUM - 1) / THREAD_NUM; // Initialize number of blocks\n",
        "\n",
        "  // Declaration of I/O variables\n",
        "  float* h_in;\n",
        "  float* h_out; // Host (i.e. CPU) variables\n",
        "  float* d_in;\n",
        "  float* d_out; // Device (i.e. GPU) variables\n",
        "  \n",
        "  // Print current specifications\n",
        "  printf(\"\\n%s\\n%s: %d\\n%s: %d\\n%s: %d\\n\\n\",\n",
        "  \"-- 1-D Convolution --\",\n",
        "  \"Vector size\", VECTOR_SIZE,\n",
        "  \"Number of threads\", THREAD_NUM,\n",
        "  \"Number of blocks\", numBlocks\n",
        "  );\n",
        "\n",
        "  // STEP 1: Allocate HOST memory\n",
        "\n",
        "  h_in = (float*)malloc(VECTOR_BYTES);\n",
        "  h_out = (float*)malloc(VECTOR_BYTES);\n",
        "\n",
        "  // Initialization of data\n",
        "\n",
        "  for (int i = 0; i < VECTOR_SIZE; i++){\n",
        "    h_in[i] = float(i);\n",
        "  }\n",
        "\n",
        "  // STEP 2: Allocate DEVICE memory \n",
        "\n",
        "  cudaMalloc((void**)&d_in, VECTOR_BYTES);\n",
        "  cudaMalloc((void**)&d_out, VECTOR_BYTES);\n",
        "\n",
        "  // STEP 3: Transfer data from host to device memory\n",
        "\n",
        "  cudaMemcpy(d_in, h_in, VECTOR_BYTES, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_out, h_out, VECTOR_BYTES, cudaMemcpyHostToDevice);\n",
        "\n",
        "  // STEP 4: Execute (convolution) kernel\n",
        "\n",
        "  for (int j = 0; j < RUN_CNT; j++)\n",
        "    convolution<<<numBlocks, THREAD_NUM>>>(d_in, d_out, VECTOR_SIZE);\n",
        "\n",
        "  // STEP 5: Transfer data back to host memory\n",
        "\n",
        "  cudaMemcpy(h_out, d_out, VECTOR_BYTES, cudaMemcpyDeviceToHost);\n",
        "\n",
        "  // Error Checking\n",
        "  int errorCount = 0;\n",
        "  for(int k = 0; k < VECTOR_SIZE - 2; k++) \n",
        "  {\n",
        "    if ( (h_in[k] + h_in[k+1] + h_in[k+2]) / 3.0f != h_out[k])\n",
        "      errorCount++;\n",
        "  }\n",
        "\n",
        "  printf(\"Error count: %d\\n\", errorCount);\n",
        "\n",
        "  // STEP 6: Deallocate HOST memory\n",
        "\n",
        "  free(h_in);\n",
        "  free(h_out);\n",
        "  \n",
        "  // STEP 7: Deallocate DEVICE memory\n",
        "\n",
        "  cudaFree(d_in);\n",
        "  cudaFree(d_out);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "dAbuEN6zYYIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc CUDA_1_1K_22.cu -o CUDA_1_1K_22\n",
        "nvprof ./CUDA_1_1K_22"
      ],
      "metadata": {
        "id": "P63N1XaNMZrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector Size: `2^24`"
      ],
      "metadata": {
        "id": "8p9uPH18YmXB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of Threads: `256`"
      ],
      "metadata": {
        "id": "x2KX_TkJYmXB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7h5vr8HQYmXB"
      },
      "outputs": [],
      "source": [
        "%%writefile CUDA_1_256_24.cu\n",
        "\n",
        "#include<stdio.h>\n",
        "#include<stdlib.h>\n",
        "\n",
        "__global__ \n",
        "void convolution(float* in, float* out, int size)\n",
        "{\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < size - 2; i += stride) {\n",
        "    out[i] = (in[i] + in[i+1] + in[i+2]) / 3.0f;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main ()\n",
        "{\n",
        "\n",
        "  // Initialization of constant variables\n",
        "  const int VECTOR_SIZE = 1 << 24; // Modify depending on the needed value\n",
        "  const int VECTOR_BYTES = VECTOR_SIZE * sizeof(float);\n",
        "  const int THREAD_NUM = 256; // Modify depending on the needed value\n",
        "  const int RUN_CNT = 30; // Modify depending on the needed value \n",
        "\n",
        "  int numBlocks = (VECTOR_SIZE + THREAD_NUM - 1) / THREAD_NUM; // Initialize number of blocks\n",
        "\n",
        "  // Declaration of I/O variables\n",
        "  float* h_in;\n",
        "  float* h_out; // Host (i.e. CPU) variables\n",
        "  float* d_in;\n",
        "  float* d_out; // Device (i.e. GPU) variables\n",
        "  \n",
        "  // Print current specifications\n",
        "  printf(\"\\n%s\\n%s: %d\\n%s: %d\\n%s: %d\\n\\n\",\n",
        "  \"-- 1-D Convolution --\",\n",
        "  \"Vector size\", VECTOR_SIZE,\n",
        "  \"Number of threads\", THREAD_NUM,\n",
        "  \"Number of blocks\", numBlocks\n",
        "  );\n",
        "\n",
        "  // STEP 1: Allocate HOST memory\n",
        "\n",
        "  h_in = (float*)malloc(VECTOR_BYTES);\n",
        "  h_out = (float*)malloc(VECTOR_BYTES);\n",
        "\n",
        "  // Initialization of data\n",
        "\n",
        "  for (int i = 0; i < VECTOR_SIZE; i++){\n",
        "    h_in[i] = float(i);\n",
        "  }\n",
        "\n",
        "  // STEP 2: Allocate DEVICE memory \n",
        "\n",
        "  cudaMalloc((void**)&d_in, VECTOR_BYTES);\n",
        "  cudaMalloc((void**)&d_out, VECTOR_BYTES);\n",
        "\n",
        "  // STEP 3: Transfer data from host to device memory\n",
        "\n",
        "  cudaMemcpy(d_in, h_in, VECTOR_BYTES, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_out, h_out, VECTOR_BYTES, cudaMemcpyHostToDevice);\n",
        "\n",
        "  // STEP 4: Execute (convolution) kernel\n",
        "\n",
        "  for (int j = 0; j < RUN_CNT; j++)\n",
        "    convolution<<<numBlocks, THREAD_NUM>>>(d_in, d_out, VECTOR_SIZE);\n",
        "\n",
        "  // STEP 5: Transfer data back to host memory\n",
        "\n",
        "  cudaMemcpy(h_out, d_out, VECTOR_BYTES, cudaMemcpyDeviceToHost);\n",
        "\n",
        "  // Error Checking\n",
        "  int errorCount = 0;\n",
        "  for(int k = 0; k < VECTOR_SIZE - 2; k++) \n",
        "  {\n",
        "    if ( (h_in[k] + h_in[k+1] + h_in[k+2]) / 3.0f != h_out[k])\n",
        "      errorCount++;\n",
        "  }\n",
        "\n",
        "  printf(\"Error count: %d\\n\", errorCount);\n",
        "\n",
        "  // STEP 6: Deallocate HOST memory\n",
        "\n",
        "  free(h_in);\n",
        "  free(h_out);\n",
        "  \n",
        "  // STEP 7: Deallocate DEVICE memory\n",
        "\n",
        "  cudaFree(d_in);\n",
        "  cudaFree(d_out);\n",
        "\n",
        "  return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc CUDA_1_256_24.cu -o CUDA_1_256_24\n",
        "nvprof ./CUDA_1_256_24"
      ],
      "metadata": {
        "id": "enOQ_6gfMgbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of Threads: `512`"
      ],
      "metadata": {
        "id": "5dXEfUl8YmXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile CUDA_1_512_24.cu\n",
        "\n",
        "#include<stdio.h>\n",
        "#include<stdlib.h>\n",
        "\n",
        "__global__ \n",
        "void convolution(float* in, float* out, int size)\n",
        "{\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < size - 2; i += stride) {\n",
        "    out[i] = (in[i] + in[i+1] + in[i+2]) / 3.0f;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main ()\n",
        "{\n",
        "\n",
        "  // Initialization of constant variables\n",
        "  const int VECTOR_SIZE = 1 << 24; // Modify depending on the needed value\n",
        "  const int VECTOR_BYTES = VECTOR_SIZE * sizeof(float);\n",
        "  const int THREAD_NUM = 512; // Modify depending on the needed value\n",
        "  const int RUN_CNT = 30; // Modify depending on the needed value \n",
        "\n",
        "  int numBlocks = (VECTOR_SIZE + THREAD_NUM - 1) / THREAD_NUM; // Initialize number of blocks\n",
        "\n",
        "  // Declaration of I/O variables\n",
        "  float* h_in;\n",
        "  float* h_out; // Host (i.e. CPU) variables\n",
        "  float* d_in;\n",
        "  float* d_out; // Device (i.e. GPU) variables\n",
        "  \n",
        "  // Print current specifications\n",
        "  printf(\"\\n%s\\n%s: %d\\n%s: %d\\n%s: %d\\n\\n\",\n",
        "  \"-- 1-D Convolution --\",\n",
        "  \"Vector size\", VECTOR_SIZE,\n",
        "  \"Number of threads\", THREAD_NUM,\n",
        "  \"Number of blocks\", numBlocks\n",
        "  );\n",
        "\n",
        "  // STEP 1: Allocate HOST memory\n",
        "\n",
        "  h_in = (float*)malloc(VECTOR_BYTES);\n",
        "  h_out = (float*)malloc(VECTOR_BYTES);\n",
        "\n",
        "  // Initialization of data\n",
        "\n",
        "  for (int i = 0; i < VECTOR_SIZE; i++){\n",
        "    h_in[i] = float(i);\n",
        "  }\n",
        "\n",
        "  // STEP 2: Allocate DEVICE memory \n",
        "\n",
        "  cudaMalloc((void**)&d_in, VECTOR_BYTES);\n",
        "  cudaMalloc((void**)&d_out, VECTOR_BYTES);\n",
        "\n",
        "  // STEP 3: Transfer data from host to device memory\n",
        "\n",
        "  cudaMemcpy(d_in, h_in, VECTOR_BYTES, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_out, h_out, VECTOR_BYTES, cudaMemcpyHostToDevice);\n",
        "\n",
        "  // STEP 4: Execute (convolution) kernel\n",
        "\n",
        "  for (int j = 0; j < RUN_CNT; j++)\n",
        "    convolution<<<numBlocks, THREAD_NUM>>>(d_in, d_out, VECTOR_SIZE);\n",
        "\n",
        "  // STEP 5: Transfer data back to host memory\n",
        "\n",
        "  cudaMemcpy(h_out, d_out, VECTOR_BYTES, cudaMemcpyDeviceToHost);\n",
        "\n",
        "  // Error Checking\n",
        "  int errorCount = 0;\n",
        "  for(int k = 0; k < VECTOR_SIZE - 2; k++) \n",
        "  {\n",
        "    if ( (h_in[k] + h_in[k+1] + h_in[k+2]) / 3.0f != h_out[k])\n",
        "      errorCount++;\n",
        "  }\n",
        "\n",
        "  printf(\"Error count: %d\\n\", errorCount);\n",
        "\n",
        "  // STEP 6: Deallocate HOST memory\n",
        "\n",
        "  free(h_in);\n",
        "  free(h_out);\n",
        "  \n",
        "  // STEP 7: Deallocate DEVICE memory\n",
        "\n",
        "  cudaFree(d_in);\n",
        "  cudaFree(d_out);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "nrqn6IRqYmXC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1610a7c4-2bfe-4e59-9e34-98830e13a0ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing CUDA_1_512_24.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc CUDA_1_512_24.cu -o CUDA_1_512_24\n",
        "nvprof ./CUDA_1_512_24"
      ],
      "metadata": {
        "id": "NM8BefLPMjOT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30a05428-8fec-4f5b-c3f4-7e595b688ee9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-- 1-D Convolution --\n",
            "Vector size: 16777216\n",
            "Number of threads: 512\n",
            "Number of blocks: 32768\n",
            "\n",
            "==860== NVPROF is profiling process 860, command: ./CUDA_1_512_24\n",
            "Error count: 0\n",
            "==860== Profiling application: ./CUDA_1_512_24\n",
            "==860== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   49.24%  68.031ms         1  68.031ms  68.031ms  68.031ms  [CUDA memcpy DtoH]\n",
            "                   29.03%  40.110ms         2  20.055ms  15.570ms  24.540ms  [CUDA memcpy HtoD]\n",
            "                   21.73%  30.028ms        30  1.0009ms  997.91us  1.0035ms  convolution(float*, float*, int)\n",
            "      API calls:   72.75%  386.52ms         2  193.26ms  223.73us  386.29ms  cudaMalloc\n",
            "                   26.49%  140.73ms         3  46.910ms  15.791ms  99.976ms  cudaMemcpy\n",
            "                    0.49%  2.6154ms         2  1.3077ms  336.63us  2.2788ms  cudaFree\n",
            "                    0.18%  968.94us         1  968.94us  968.94us  968.94us  cuDeviceGetPCIBusId\n",
            "                    0.04%  236.68us        30  7.8890us  5.4950us  55.335us  cudaLaunchKernel\n",
            "                    0.04%  199.44us       101  1.9740us     284ns  72.821us  cuDeviceGetAttribute\n",
            "                    0.01%  31.275us         1  31.275us  31.275us  31.275us  cuDeviceGetName\n",
            "                    0.00%  2.4960us         3     832ns     362ns  1.7650us  cuDeviceGetCount\n",
            "                    0.00%  1.0990us         2     549ns     340ns     759ns  cuDeviceGet\n",
            "                    0.00%     638ns         1     638ns     638ns     638ns  cuDeviceTotalMem\n",
            "                    0.00%     624ns         1     624ns     624ns     624ns  cuModuleGetLoadingMode\n",
            "                    0.00%     446ns         1     446ns     446ns     446ns  cuDeviceGetUuid\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of Threads: `1024`"
      ],
      "metadata": {
        "id": "cP12KjjsYmXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile CUDA_1_1K_24.cu\n",
        "\n",
        "#include<stdio.h>\n",
        "#include<stdlib.h>\n",
        "\n",
        "__global__ \n",
        "void convolution(float* in, float* out, int size)\n",
        "{\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < size - 2; i += stride) {\n",
        "    out[i] = (in[i] + in[i+1] + in[i+2]) / 3.0f;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main ()\n",
        "{\n",
        "\n",
        "  // Initialization of constant variables\n",
        "  const int VECTOR_SIZE = 1 << 24; // Modify depending on the needed value\n",
        "  const int VECTOR_BYTES = VECTOR_SIZE * sizeof(float);\n",
        "  const int THREAD_NUM = 1024; // Modify depending on the needed value\n",
        "  const int RUN_CNT = 30; // Modify depending on the needed value \n",
        "\n",
        "  int numBlocks = (VECTOR_SIZE + THREAD_NUM - 1) / THREAD_NUM; // Initialize number of blocks\n",
        "\n",
        "  // Declaration of I/O variables\n",
        "  float* h_in;\n",
        "  float* h_out; // Host (i.e. CPU) variables\n",
        "  float* d_in;\n",
        "  float* d_out; // Device (i.e. GPU) variables\n",
        "  \n",
        "  // Print current specifications\n",
        "  printf(\"\\n%s\\n%s: %d\\n%s: %d\\n%s: %d\\n\\n\",\n",
        "  \"-- 1-D Convolution --\",\n",
        "  \"Vector size\", VECTOR_SIZE,\n",
        "  \"Number of threads\", THREAD_NUM,\n",
        "  \"Number of blocks\", numBlocks\n",
        "  );\n",
        "\n",
        "  // STEP 1: Allocate HOST memory\n",
        "\n",
        "  h_in = (float*)malloc(VECTOR_BYTES);\n",
        "  h_out = (float*)malloc(VECTOR_BYTES);\n",
        "\n",
        "  // Initialization of data\n",
        "\n",
        "  for (int i = 0; i < VECTOR_SIZE; i++){\n",
        "    h_in[i] = float(i);\n",
        "  }\n",
        "\n",
        "  // STEP 2: Allocate DEVICE memory \n",
        "\n",
        "  cudaMalloc((void**)&d_in, VECTOR_BYTES);\n",
        "  cudaMalloc((void**)&d_out, VECTOR_BYTES);\n",
        "\n",
        "  // STEP 3: Transfer data from host to device memory\n",
        "\n",
        "  cudaMemcpy(d_in, h_in, VECTOR_BYTES, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_out, h_out, VECTOR_BYTES, cudaMemcpyHostToDevice);\n",
        "\n",
        "  // STEP 4: Execute (convolution) kernel\n",
        "\n",
        "  for (int j = 0; j < RUN_CNT; j++)\n",
        "    convolution<<<numBlocks, THREAD_NUM>>>(d_in, d_out, VECTOR_SIZE);\n",
        "\n",
        "  // STEP 5: Transfer data back to host memory\n",
        "\n",
        "  cudaMemcpy(h_out, d_out, VECTOR_BYTES, cudaMemcpyDeviceToHost);\n",
        "\n",
        "  // Error Checking\n",
        "  int errorCount = 0;\n",
        "  for(int k = 0; k < VECTOR_SIZE - 2; k++) \n",
        "  {\n",
        "    if ( (h_in[k] + h_in[k+1] + h_in[k+2]) / 3.0f != h_out[k])\n",
        "      errorCount++;\n",
        "  }\n",
        "\n",
        "  printf(\"Error count: %d\\n\", errorCount);\n",
        "\n",
        "  // STEP 6: Deallocate HOST memory\n",
        "\n",
        "  free(h_in);\n",
        "  free(h_out);\n",
        "  \n",
        "  // STEP 7: Deallocate DEVICE memory\n",
        "\n",
        "  cudaFree(d_in);\n",
        "  cudaFree(d_out);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "rSQ7YdVpYmXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc CUDA_1_1K_24.cu -o CUDA_1_1K_24\n",
        "nvprof ./CUDA_1_1K_24"
      ],
      "metadata": {
        "id": "N9Bm9SW-MnOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQnsXyxpxFV0"
      },
      "source": [
        "#IMPLEMENTATION #2: Unified Memory Introduced in CUDA 6"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector Size: `2^20`"
      ],
      "metadata": {
        "id": "d5jNfzlNYr9n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of Threads: `256`"
      ],
      "metadata": {
        "id": "dUpVr4B3Yvp3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OofuMNXSwfMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cbef480-847e-4e57-8d1d-39f5918be768"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting CUDA_2.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile CUDA_2.cu\n",
        "\n",
        "#include<stdio.h>\n",
        "#include<stdlib.h>\n",
        "\n",
        "__global__ \n",
        "void convolution(float* in, float* out, int size)\n",
        "{\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < size - 2; i += stride) {\n",
        "    out[i] = (in[i] + in[i+1] + in[i+2]) / 3.0f;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "\n",
        "  // Initialization of constant variables\n",
        "  const int vector = 1 << 20; //AKA ARRAY_SIZE (Modify depending on the needed value)\n",
        "  const int ARRAY_BYTES = vector * sizeof(float);\n",
        "  const int threads = 256; //Modify depending on the needed value\n",
        "  const int count = 30;\n",
        "  \n",
        "  // Declaration of I/O variables/arrays\n",
        "  float* in;\n",
        "  float* out;\n",
        "  \n",
        "  cudaMallocManaged(&in, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&out, ARRAY_BYTES);\n",
        "\n",
        "  // Data Initialization \n",
        "  for (int i = 0; i < vector; i++){\n",
        "    in[i] = float(i);\n",
        "  }\n",
        "\n",
        "  //Execute kernel\n",
        "  int numBlocks = (vector + threads - 1)/threads;\n",
        "  for (int j = 0; j < count; j++){\n",
        "    convolution<<<numBlocks, threads>>>(in, out, vector);\n",
        "  }\n",
        "  \n",
        "  cudaDeviceSynchronize();\n",
        "  /*\n",
        "  for (int i = 0; i < vector - 2; i++){\n",
        "    printf(\"%.6f \\n\", out[i]);\n",
        "  }\n",
        "  */\n",
        "  // Error Checking\n",
        "  int errorCount = 0;\n",
        "  for(int k = 0; k < vector - 2; k++) \n",
        "  {\n",
        "    if ( (in[k] + in[k+1] + in[k+2]) / 3.0f != out[k])\n",
        "      errorCount++;\n",
        "  }\n",
        "\n",
        "  printf(\"Error count: %d\\n\", errorCount);\n",
        "\n",
        "  // Deallocate DEVICE memory\n",
        "  cudaFree(in);\n",
        "  cudaFree(out);\n",
        "\n",
        "  return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wb_ZAGVllhVU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aab625f7-ba97-4682-d9fe-c206125d0268"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==8580== NVPROF is profiling process 8580, command: ./CUDA_2\n",
            "Error count: 0\n",
            "==8580== Profiling application: ./CUDA_2\n",
            "==8580== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  4.5540ms        30  151.80us  60.800us  2.7832ms  convolution(float*, float*, int)\n",
            "      API calls:   96.68%  157.15ms         2  78.573ms  37.068us  157.11ms  cudaMallocManaged\n",
            "                    2.69%  4.3679ms         1  4.3679ms  4.3679ms  4.3679ms  cudaDeviceSynchronize\n",
            "                    0.39%  628.11us         2  314.05us  275.58us  352.53us  cudaFree\n",
            "                    0.15%  248.19us        30  8.2720us  4.5380us  46.760us  cudaLaunchKernel\n",
            "                    0.07%  120.70us       101  1.1950us     140ns  51.514us  cuDeviceGetAttribute\n",
            "                    0.02%  26.914us         1  26.914us  26.914us  26.914us  cuDeviceGetName\n",
            "                    0.00%  6.2700us         1  6.2700us  6.2700us  6.2700us  cuDeviceGetPCIBusId\n",
            "                    0.00%  3.5590us         3  1.1860us     194ns  1.8090us  cuDeviceGetCount\n",
            "                    0.00%  1.5540us         2     777ns     459ns  1.0950us  cuDeviceGet\n",
            "                    0.00%     523ns         1     523ns     523ns     523ns  cuModuleGetLoadingMode\n",
            "                    0.00%     492ns         1     492ns     492ns     492ns  cuDeviceTotalMem\n",
            "                    0.00%     248ns         1     248ns     248ns     248ns  cuDeviceGetUuid\n",
            "\n",
            "==8580== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "      37  110.70KB  4.0000KB  984.00KB  4.000000MB  443.9950us  Host To Device\n",
            "      48  170.67KB  4.0000KB  0.9961MB  8.000000MB  720.4710us  Device To Host\n",
            "      19         -         -         -           -  2.725606ms  Gpu page fault groups\n",
            "Total CPU Page faults: 36\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "%%shell\n",
        "nvcc CUDA_2.cu -o CUDA_2\n",
        "nvprof ./CUDA_2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of Threads: `512`"
      ],
      "metadata": {
        "id": "xu_XvLseY3FJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOns-dFu-qKh"
      },
      "outputs": [],
      "source": [
        "%%writefile CUDA_2.cu\n",
        "\n",
        "#include<stdio.h>\n",
        "#include<stdlib.h>\n",
        "\n",
        "__global__ \n",
        "void convolution(float* in, float* out, int size)\n",
        "{\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < size - 2; i += stride) {\n",
        "    out[i] = (in[i] + in[i+1] + in[i+2]) / 3.0f;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "\n",
        "  // Initialization of constant variables\n",
        "  const int vector = 1 << 20; //AKA ARRAY_SIZE (Modify depending on the needed value)\n",
        "  const int ARRAY_BYTES = vector * sizeof(float);\n",
        "  const int threads = 512; //Modify depending on the needed value\n",
        "  const int count = 30;\n",
        "  \n",
        "  // Declaration of I/O variables/arrays\n",
        "  float* in;\n",
        "  float* out;\n",
        "  \n",
        "  cudaMallocManaged(&in, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&out, ARRAY_BYTES);\n",
        "\n",
        "  // Data Initialization \n",
        "  for (int i = 0; i < vector; i++){\n",
        "    in[i] = float(i);\n",
        "  }\n",
        "\n",
        "  //Execute kernel\n",
        "  int numBlocks = (vector + threads - 1)/threads;\n",
        "  for (int j = 0; j < count; j++){\n",
        "    convolution<<<numBlocks, threads>>>(in, out, vector);\n",
        "  }\n",
        "  \n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  for (int i = 0; i < vector - 2; i++){\n",
        "    printf(\"%.6f \\n\", out[i]);\n",
        "  }\n",
        "\n",
        "  // Error Checking\n",
        "  int errorCount = 0;\n",
        "  for(int k = 0; k < vector - 2; k++) \n",
        "  {\n",
        "    if ( (in[k] + in[k+1] + in[k+2]) / 3.0f != out[k])\n",
        "      errorCount++;\n",
        "  }\n",
        "\n",
        "  printf(\"Error count: %d\\n\", errorCount);\n",
        "\n",
        "  // Deallocate DEVICE memory\n",
        "  cudaFree(in);\n",
        "  cudaFree(out);\n",
        "\n",
        "  return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhDJjllP-qKh"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "nvcc CUDA_2.cu -o CUDA_2\n",
        "nvprof ./CUDA_2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of Threads: `1024`"
      ],
      "metadata": {
        "id": "N0GvKcw5Y8Oz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQUsk09h-tYX"
      },
      "outputs": [],
      "source": [
        "%%writefile CUDA_2.cu\n",
        "\n",
        "#include<stdio.h>\n",
        "#include<stdlib.h>\n",
        "\n",
        "__global__ \n",
        "void convolution(float* in, float* out, int size)\n",
        "{\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < size - 2; i += stride) {\n",
        "    out[i] = (in[i] + in[i+1] + in[i+2]) / 3.0f;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "\n",
        "  // Initialization of constant variables\n",
        "  const int vector = 1 << 20; //AKA ARRAY_SIZE (Modify depending on the needed value)\n",
        "  const int ARRAY_BYTES = vector * sizeof(float);\n",
        "  const int threads = 1024; //Modify depending on the needed value\n",
        "  const int count = 30;\n",
        "  \n",
        "  // Declaration of I/O variables/arrays\n",
        "  float* in;\n",
        "  float* out;\n",
        "  \n",
        "  cudaMallocManaged(&in, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&out, ARRAY_BYTES);\n",
        "\n",
        "  // Data Initialization \n",
        "  for (int i = 0; i < vector; i++){\n",
        "    in[i] = float(i);\n",
        "  }\n",
        "\n",
        "  //Execute kernel\n",
        "  int numBlocks = (vector + threads - 1)/threads;\n",
        "  for (int j = 0; j < count; j++){\n",
        "    convolution<<<numBlocks, threads>>>(in, out, vector);\n",
        "  }\n",
        "  \n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  for (int i = 0; i < vector - 2; i++){\n",
        "    printf(\"%.6f \\n\", out[i]);\n",
        "  }\n",
        "\n",
        "  // Error Checking\n",
        "  int errorCount = 0;\n",
        "  for(int k = 0; k < vector - 2; k++) \n",
        "  {\n",
        "    if ( (in[k] + in[k+1] + in[k+2]) / 3.0f != out[k])\n",
        "      errorCount++;\n",
        "  }\n",
        "\n",
        "  printf(\"Error count: %d\\n\", errorCount);\n",
        "\n",
        "  // Deallocate DEVICE memory\n",
        "  cudaFree(in);\n",
        "  cudaFree(out);\n",
        "\n",
        "  return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ACBTd4l-tYd"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "nvcc CUDA_2.cu -o CUDA_2\n",
        "nvprof ./CUDA_2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector Size: `2^22`"
      ],
      "metadata": {
        "id": "_-LDgbMZZEub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of Threads: `256`"
      ],
      "metadata": {
        "id": "G7kc12xXZEuh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMlTG3Qn-0zf"
      },
      "outputs": [],
      "source": [
        "%%writefile CUDA_2.cu\n",
        "\n",
        "#include<stdio.h>\n",
        "#include<stdlib.h>\n",
        "\n",
        "__global__ \n",
        "void convolution(float* in, float* out, int size)\n",
        "{\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < size - 2; i += stride) {\n",
        "    out[i] = (in[i] + in[i+1] + in[i+2]) / 3.0f;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "\n",
        "  // Initialization of constant variables\n",
        "  const int vector = 1 << 22; //AKA ARRAY_SIZE (Modify depending on the needed value)\n",
        "  const int ARRAY_BYTES = vector * sizeof(float);\n",
        "  const int threads = 256; //Modify depending on the needed value\n",
        "  const int count = 30;\n",
        "  \n",
        "  // Declaration of I/O variables/arrays\n",
        "  float* in;\n",
        "  float* out;\n",
        "  \n",
        "  cudaMallocManaged(&in, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&out, ARRAY_BYTES);\n",
        "\n",
        "  // Data Initialization \n",
        "  for (int i = 0; i < vector; i++){\n",
        "    in[i] = float(i);\n",
        "  }\n",
        "\n",
        "  //Execute kernel\n",
        "  int numBlocks = (vector + threads - 1)/threads;\n",
        "  for (int j = 0; j < count; j++){\n",
        "    convolution<<<numBlocks, threads>>>(in, out, vector);\n",
        "  }\n",
        "  \n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  for (int i = 0; i < vector - 2; i++){\n",
        "    printf(\"%.6f \\n\", out[i]);\n",
        "  }\n",
        "\n",
        "  // Error Checking\n",
        "  int errorCount = 0;\n",
        "  for(int k = 0; k < vector - 2; k++) \n",
        "  {\n",
        "    if ( (in[k] + in[k+1] + in[k+2]) / 3.0f != out[k])\n",
        "      errorCount++;\n",
        "  }\n",
        "\n",
        "  printf(\"Error count: %d\\n\", errorCount);\n",
        "\n",
        "  // Deallocate DEVICE memory\n",
        "  cudaFree(in);\n",
        "  cudaFree(out);\n",
        "\n",
        "  return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gD3Je2A0-0zm"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "nvcc CUDA_2.cu -o CUDA_2\n",
        "nvprof ./CUDA_2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of Threads: `512`"
      ],
      "metadata": {
        "id": "lrHtP7KOZEui"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcFxPorF-2xE"
      },
      "outputs": [],
      "source": [
        "%%writefile CUDA_2.cu\n",
        "\n",
        "#include<stdio.h>\n",
        "#include<stdlib.h>\n",
        "\n",
        "__global__ \n",
        "void convolution(float* in, float* out, int size)\n",
        "{\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < size - 2; i += stride) {\n",
        "    out[i] = (in[i] + in[i+1] + in[i+2]) / 3.0f;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "\n",
        "  // Initialization of constant variables\n",
        "  const int vector = 1 << 22; //AKA ARRAY_SIZE (Modify depending on the needed value)\n",
        "  const int ARRAY_BYTES = vector * sizeof(float);\n",
        "  const int threads = 512; //Modify depending on the needed value\n",
        "  const int count = 30;\n",
        "  \n",
        "  // Declaration of I/O variables/arrays\n",
        "  float* in;\n",
        "  float* out;\n",
        "  \n",
        "  cudaMallocManaged(&in, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&out, ARRAY_BYTES);\n",
        "\n",
        "  // Data Initialization \n",
        "  for (int i = 0; i < vector; i++){\n",
        "    in[i] = float(i);\n",
        "  }\n",
        "\n",
        "  //Execute kernel\n",
        "  int numBlocks = (vector + threads - 1)/threads;\n",
        "  for (int j = 0; j < count; j++){\n",
        "    convolution<<<numBlocks, threads>>>(in, out, vector);\n",
        "  }\n",
        "  \n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  for (int i = 0; i < vector - 2; i++){\n",
        "    printf(\"%.6f \\n\", out[i]);\n",
        "  }\n",
        "\n",
        "  // Error Checking\n",
        "  int errorCount = 0;\n",
        "  for(int k = 0; k < vector - 2; k++) \n",
        "  {\n",
        "    if ( (in[k] + in[k+1] + in[k+2]) / 3.0f != out[k])\n",
        "      errorCount++;\n",
        "  }\n",
        "\n",
        "  printf(\"Error count: %d\\n\", errorCount);\n",
        "\n",
        "  // Deallocate DEVICE memory\n",
        "  cudaFree(in);\n",
        "  cudaFree(out);\n",
        "\n",
        "  return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73oMkvNa-2xJ"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "nvcc CUDA_2.cu -o CUDA_2\n",
        "nvprof ./CUDA_2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of Threads: `1024`"
      ],
      "metadata": {
        "id": "mCIEFLRgZEui"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLeTH4hw-4qs"
      },
      "outputs": [],
      "source": [
        "%%writefile CUDA_2.cu\n",
        "\n",
        "#include<stdio.h>\n",
        "#include<stdlib.h>\n",
        "\n",
        "__global__ \n",
        "void convolution(float* in, float* out, int size)\n",
        "{\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < size - 2; i += stride) {\n",
        "    out[i] = (in[i] + in[i+1] + in[i+2]) / 3.0f;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "\n",
        "  // Initialization of constant variables\n",
        "  const int vector = 1 << 22; //AKA ARRAY_SIZE (Modify depending on the needed value)\n",
        "  const int ARRAY_BYTES = vector * sizeof(float);\n",
        "  const int threads = 1024; //Modify depending on the needed value\n",
        "  const int count = 30;\n",
        "  \n",
        "  // Declaration of I/O variables/arrays\n",
        "  float* in;\n",
        "  float* out;\n",
        "  \n",
        "  cudaMallocManaged(&in, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&out, ARRAY_BYTES);\n",
        "\n",
        "  // Data Initialization \n",
        "  for (int i = 0; i < vector; i++){\n",
        "    in[i] = float(i);\n",
        "  }\n",
        "\n",
        "  //Execute kernel\n",
        "  int numBlocks = (vector + threads - 1)/threads;\n",
        "  for (int j = 0; j < count; j++){\n",
        "    convolution<<<numBlocks, threads>>>(in, out, vector);\n",
        "  }\n",
        "  \n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  for (int i = 0; i < vector - 2; i++){\n",
        "    printf(\"%.6f \\n\", out[i]);\n",
        "  }\n",
        "\n",
        "  // Error Checking\n",
        "  int errorCount = 0;\n",
        "  for(int k = 0; k < vector - 2; k++) \n",
        "  {\n",
        "    if ( (in[k] + in[k+1] + in[k+2]) / 3.0f != out[k])\n",
        "      errorCount++;\n",
        "  }\n",
        "\n",
        "  printf(\"Error count: %d\\n\", errorCount);\n",
        "\n",
        "  // Deallocate DEVICE memory\n",
        "  cudaFree(in);\n",
        "  cudaFree(out);\n",
        "\n",
        "  return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzaVAQM3-4qx"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "nvcc CUDA_2.cu -o CUDA_2\n",
        "nvprof ./CUDA_2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector Size: `2^24`"
      ],
      "metadata": {
        "id": "gaNamsgNZP-T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of Threads: `256`"
      ],
      "metadata": {
        "id": "rwsSjHirZP-a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HS2Ty_n-63o"
      },
      "outputs": [],
      "source": [
        "%%writefile CUDA_2.cu\n",
        "\n",
        "#include<stdio.h>\n",
        "#include<stdlib.h>\n",
        "\n",
        "__global__ \n",
        "void convolution(float* in, float* out, int size)\n",
        "{\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < size - 2; i += stride) {\n",
        "    out[i] = (in[i] + in[i+1] + in[i+2]) / 3.0f;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "\n",
        "  // Initialization of constant variables\n",
        "  const int vector = 1 << 24; //AKA ARRAY_SIZE (Modify depending on the needed value)\n",
        "  const int ARRAY_BYTES = vector * sizeof(float);\n",
        "  const int threads = 256; //Modify depending on the needed value\n",
        "  const int count = 30;\n",
        "  \n",
        "  // Declaration of I/O variables/arrays\n",
        "  float* in;\n",
        "  float* out;\n",
        "  \n",
        "  cudaMallocManaged(&in, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&out, ARRAY_BYTES);\n",
        "\n",
        "  // Data Initialization \n",
        "  for (int i = 0; i < vector; i++){\n",
        "    in[i] = float(i);\n",
        "  }\n",
        "\n",
        "  //Execute kernel\n",
        "  int numBlocks = (vector + threads - 1)/threads;\n",
        "  for (int j = 0; j < count; j++){\n",
        "    convolution<<<numBlocks, threads>>>(in, out, vector);\n",
        "  }\n",
        "  \n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  for (int i = 0; i < vector - 2; i++){\n",
        "    printf(\"%.6f \\n\", out[i]);\n",
        "  }\n",
        "\n",
        "  // Error Checking\n",
        "  int errorCount = 0;\n",
        "  for(int k = 0; k < vector - 2; k++) \n",
        "  {\n",
        "    if ( (in[k] + in[k+1] + in[k+2]) / 3.0f != out[k])\n",
        "      errorCount++;\n",
        "  }\n",
        "\n",
        "  printf(\"Error count: %d\\n\", errorCount);\n",
        "\n",
        "  // Deallocate DEVICE memory\n",
        "  cudaFree(in);\n",
        "  cudaFree(out);\n",
        "\n",
        "  return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ah_2crj_-63u"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "nvcc CUDA_2.cu -o CUDA_2\n",
        "nvprof ./CUDA_2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of Threads: `512`"
      ],
      "metadata": {
        "id": "2gOCE_NbZP-c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXsr71YQ-8tC"
      },
      "outputs": [],
      "source": [
        "%%writefile CUDA_2.cu\n",
        "\n",
        "#include<stdio.h>\n",
        "#include<stdlib.h>\n",
        "\n",
        "__global__ \n",
        "void convolution(float* in, float* out, int size)\n",
        "{\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < size - 2; i += stride) {\n",
        "    out[i] = (in[i] + in[i+1] + in[i+2]) / 3.0f;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "\n",
        "  // Initialization of constant variables\n",
        "  const int vector = 1 << 24; //AKA ARRAY_SIZE (Modify depending on the needed value)\n",
        "  const int ARRAY_BYTES = vector * sizeof(float);\n",
        "  const int threads = 512; //Modify depending on the needed value\n",
        "  const int count = 30;\n",
        "  \n",
        "  // Declaration of I/O variables/arrays\n",
        "  float* in;\n",
        "  float* out;\n",
        "  \n",
        "  cudaMallocManaged(&in, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&out, ARRAY_BYTES);\n",
        "\n",
        "  // Data Initialization \n",
        "  for (int i = 0; i < vector; i++){\n",
        "    in[i] = float(i);\n",
        "  }\n",
        "\n",
        "  //Execute kernel\n",
        "  int numBlocks = (vector + threads - 1)/threads;\n",
        "  for (int j = 0; j < count; j++){\n",
        "    convolution<<<numBlocks, threads>>>(in, out, vector);\n",
        "  }\n",
        "  \n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  for (int i = 0; i < vector - 2; i++){\n",
        "    printf(\"%.6f \\n\", out[i]);\n",
        "  }\n",
        "\n",
        "  // Error Checking\n",
        "  int errorCount = 0;\n",
        "  for(int k = 0; k < vector - 2; k++) \n",
        "  {\n",
        "    if ( (in[k] + in[k+1] + in[k+2]) / 3.0f != out[k])\n",
        "      errorCount++;\n",
        "  }\n",
        "\n",
        "  printf(\"Error count: %d\\n\", errorCount);\n",
        "\n",
        "  // Deallocate DEVICE memory\n",
        "  cudaFree(in);\n",
        "  cudaFree(out);\n",
        "\n",
        "  return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNzLi9XP-8tH"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "nvcc CUDA_2.cu -o CUDA_2\n",
        "nvprof ./CUDA_2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of Threads: `1024`"
      ],
      "metadata": {
        "id": "KfAVn2T_ZP-d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_R2yT1Gf-_6H"
      },
      "outputs": [],
      "source": [
        "%%writefile CUDA_2.cu\n",
        "\n",
        "#include<stdio.h>\n",
        "#include<stdlib.h>\n",
        "\n",
        "__global__ \n",
        "void convolution(float* in, float* out, int size)\n",
        "{\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < size - 2; i += stride) {\n",
        "    out[i] = (in[i] + in[i+1] + in[i+2]) / 3.0f;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "\n",
        "  // Initialization of constant variables\n",
        "  const int vector = 1 << 24; //AKA ARRAY_SIZE (Modify depending on the needed value)\n",
        "  const int ARRAY_BYTES = vector * sizeof(float);\n",
        "  const int threads = 1024; //Modify depending on the needed value\n",
        "  const int count = 30;\n",
        "  \n",
        "  // Declaration of I/O variables/arrays\n",
        "  float* in;\n",
        "  float* out;\n",
        "  \n",
        "  cudaMallocManaged(&in, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&out, ARRAY_BYTES);\n",
        "\n",
        "  // Data Initialization \n",
        "  for (int i = 0; i < vector; i++){\n",
        "    in[i] = float(i);\n",
        "  }\n",
        "\n",
        "  //Execute kernel\n",
        "  int numBlocks = (vector + threads - 1)/threads;\n",
        "  for (int j = 0; j < count; j++){\n",
        "    convolution<<<numBlocks, threads>>>(in, out, vector);\n",
        "  }\n",
        "  \n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  for (int i = 0; i < vector - 2; i++){\n",
        "    printf(\"%.6f \\n\", out[i]);\n",
        "  }\n",
        "\n",
        "  // Error Checking\n",
        "  int errorCount = 0;\n",
        "  for(int k = 0; k < vector - 2; k++) \n",
        "  {\n",
        "    if ( (in[k] + in[k+1] + in[k+2]) / 3.0f != out[k])\n",
        "      errorCount++;\n",
        "  }\n",
        "\n",
        "  printf(\"Error count: %d\\n\", errorCount);\n",
        "\n",
        "  // Deallocate DEVICE memory\n",
        "  cudaFree(in);\n",
        "  cudaFree(out);\n",
        "\n",
        "  return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdMJ7Qmw-_6N"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "nvcc CUDA_2.cu -o CUDA_2\n",
        "nvprof ./CUDA_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1kOkamNxT45"
      },
      "source": [
        "#IMPLEMENTATION #3: Prefetching of Data with Memory Advice"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector Size: `2^20`"
      ],
      "metadata": {
        "id": "9YiwHiC2ZTO5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of Threads: `256`"
      ],
      "metadata": {
        "id": "URAJBZKLZWZV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m__zyqQvxWOg"
      },
      "outputs": [],
      "source": [
        "%%writefile CUDA_3a.cu\n",
        "\n",
        "//with maximum pre-fetching \n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "//CUDA square kernel\n",
        "__global__\n",
        "void conv(int n, float* d_out, float* d_in){\n",
        "  int index = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x*gridDim.x;\n",
        "  for(int i=index; i<n-2; i+=stride){\n",
        "    d_out[i] = (d_in[i] + d_in[i+1] + d_in[i+2])/3.0f;\n",
        "  }\n",
        "\n",
        "}\n",
        "\n",
        "int main(){\n",
        "  \n",
        "  const unsigned int ARRAY_SIZE = 1<<20; \n",
        "  const unsigned ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
        "  const int runs = 30;\n",
        "\n",
        "  //declary ARRAY\n",
        "  float *in, *out;\n",
        "  cudaMallocManaged(&in, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&out, ARRAY_BYTES);\n",
        "\n",
        "// --- prefetch the data #1---- //\n",
        "  int device = -1; //garbage value (it means NO GPU found)\n",
        "  cudaGetDevice(&device); //this will change the valeu of device \n",
        "  printf(\"Device # = %d\\n\", device);\n",
        " // cudaMemPrefetchAsync(in, ARRAY_BYTES,device,NULL);\n",
        " //Advise GPU that the 'in' array stays in the host(CPU) memory -- \"copy and paste\"\n",
        "  cudaMemAdvise(in, ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "  // Asynchronously transfer data ahead of time from GPU memory back to the host memory\n",
        "  cudaMemPrefetchAsync(in, ARRAY_BYTES, cudaCpuDeviceId, NULL); // NULL means run one stream\n",
        " //Asynchronously transfer data ahead of time to the GPU memory -- \"cut and paste\"\n",
        "  cudaMemPrefetchAsync(out, ARRAY_BYTES,device,NULL); //null means run one stream\n",
        "\n",
        "  //initialize data\n",
        "  for (int i=0; i<ARRAY_SIZE; i++)\n",
        "    in[i] = float(i);\n",
        "\n",
        "  // -- Prefetch data part #2--\n",
        "  //Advise GPU that the 'in' array is read-only\n",
        "  cudaMemAdvise(in, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "  //Copy and paste data from host memory to GPU memory\n",
        "  cudaMemPrefetchAsync(in, ARRAY_BYTES, device, NULL); //NULL means run one stream\n",
        "\n",
        "\n",
        "  //start here\n",
        "  int numThreads = 256;\n",
        "  int numBlocks = (ARRAY_SIZE+numThreads-1) / numThreads;\n",
        "  for(int i=0; i<runs; i++){\n",
        "    conv<<<numBlocks, numThreads>>>(ARRAY_SIZE,out,in);\n",
        "  }\n",
        "\n",
        "  printf(\"numThreads = %d, numBlocks = %d\\n\", numThreads, numBlocks); \n",
        "  //wait for the GPU to completerun/execution\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  //Prefetch data #3 again to omit the instance of PAGEFAULT\n",
        " // cudaMemPrefetchAsync(in, ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
        "  cudaMemPrefetchAsync(out, ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
        "\n",
        "  //check for errors\n",
        "  unsigned int err_count = 0;\n",
        "  for(int i=0; i<ARRAY_SIZE-2; i++){\n",
        "    if((in[i]+in[i+1]+in[i+2])/3.0f != out[i])\n",
        "      err_count++;\n",
        "  }\n",
        "  printf(\"\\n Error count (CUDA program): %d\\n\", err_count);\n",
        "\n",
        "\n",
        "  //free memory\n",
        "  cudaFree(in);\n",
        "  cudaFree(out);\n",
        "  \n",
        "  return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc CUDA_3a.cu -o CUDA_3a\n",
        "nvprof ./CUDA_3a"
      ],
      "metadata": {
        "id": "_u5nWr1QR2SG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of Threads: `512`"
      ],
      "metadata": {
        "id": "CotSo5cCZnb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile CUDA_3b.cu\n",
        "\n",
        "//with maximum pre-fetching \n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "//CUDA square kernel\n",
        "__global__\n",
        "void conv(int n, float* d_out, float* d_in){\n",
        "  int index = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x*gridDim.x;\n",
        "  for(int i=index; i<n-2; i+=stride){\n",
        "    d_out[i] = (d_in[i] + d_in[i+1] + d_in[i+2])/3.0f;\n",
        "  }\n",
        "\n",
        "}\n",
        "\n",
        "int main(){\n",
        "  \n",
        "  const unsigned int ARRAY_SIZE = 1<<20; \n",
        "  const unsigned ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
        "  const int runs = 30;\n",
        "\n",
        "  //declary ARRAY\n",
        "  float *in, *out;\n",
        "  cudaMallocManaged(&in, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&out, ARRAY_BYTES);\n",
        "\n",
        "// --- prefetch the data #1---- //\n",
        "  int device = -1; //garbage value (it means NO GPU found)\n",
        "  cudaGetDevice(&device); //this will change the valeu of device \n",
        "  printf(\"Device # = %d\\n\", device);\n",
        " // cudaMemPrefetchAsync(in, ARRAY_BYTES,device,NULL);\n",
        " //Advise GPU that the 'in' array stays in the host(CPU) memory -- \"copy and paste\"\n",
        "  cudaMemAdvise(in, ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "  // Asynchronously transfer data ahead of time from GPU memory back to the host memory\n",
        "  cudaMemPrefetchAsync(in, ARRAY_BYTES, cudaCpuDeviceId, NULL); // NULL means run one stream\n",
        " //Asynchronously transfer data ahead of time to the GPU memory -- \"cut and paste\"\n",
        "  cudaMemPrefetchAsync(out, ARRAY_BYTES,device,NULL); //null means run one stream\n",
        "\n",
        "  //initialize data\n",
        "  for (int i=0; i<ARRAY_SIZE; i++)\n",
        "    in[i] = float(i);\n",
        "\n",
        "  // -- Prefetch data part #2--\n",
        "  //Advise GPU that the 'in' array is read-only\n",
        "  cudaMemAdvise(in, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "  //Copy and paste data from host memory to GPU memory\n",
        "  cudaMemPrefetchAsync(in, ARRAY_BYTES, device, NULL); //NULL means run one stream\n",
        "\n",
        "\n",
        "  //start here\n",
        "  int numThreads = 512;\n",
        "  int numBlocks = (ARRAY_SIZE+numThreads-1) / numThreads;\n",
        "  for(int i=0; i<runs; i++){\n",
        "    conv<<<numBlocks, numThreads>>>(ARRAY_SIZE,out,in);\n",
        "  }\n",
        "\n",
        "  printf(\"numThreads = %d, numBlocks = %d\\n\", numThreads, numBlocks); \n",
        "  //wait for the GPU to completerun/execution\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  //Prefetch data #3 again to omit the instance of PAGEFAULT\n",
        " // cudaMemPrefetchAsync(in, ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
        "  cudaMemPrefetchAsync(out, ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
        "\n",
        "  //check for errors\n",
        "  unsigned int err_count = 0;\n",
        "  for(int i=0; i<ARRAY_SIZE-2; i++){\n",
        "    if((in[i]+in[i+1]+in[i+2])/3.0f != out[i])\n",
        "      err_count++;\n",
        "  }\n",
        "  printf(\"\\n Error count (CUDA program): %d\\n\", err_count);\n",
        "\n",
        "\n",
        "  //free memory\n",
        "  cudaFree(in);\n",
        "  cudaFree(out);\n",
        "  \n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "P93QM0mMZnb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc CUDA_3b.cu -o CUDA_3b\n",
        "nvprof ./CUDA_3b"
      ],
      "metadata": {
        "id": "x5F2_BgUA-Ne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of Threads: `1024`"
      ],
      "metadata": {
        "id": "yy2aG3XJZnnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile CUDA_3c.cu\n",
        "\n",
        "//with maximum pre-fetching \n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "//CUDA square kernel\n",
        "__global__\n",
        "void conv(int n, float* d_out, float* d_in){\n",
        "  int index = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x*gridDim.x;\n",
        "  for(int i=index; i<n-2; i+=stride){\n",
        "    d_out[i] = (d_in[i] + d_in[i+1] + d_in[i+2])/3.0f;\n",
        "  }\n",
        "\n",
        "}\n",
        "\n",
        "int main(){\n",
        "  \n",
        "  const unsigned int ARRAY_SIZE = 1<<20; \n",
        "  const unsigned ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
        "  const int runs = 30;\n",
        "\n",
        "  //declary ARRAY\n",
        "  float *in, *out;\n",
        "  cudaMallocManaged(&in, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&out, ARRAY_BYTES);\n",
        "\n",
        "// --- prefetch the data #1---- //\n",
        "  int device = -1; //garbage value (it means NO GPU found)\n",
        "  cudaGetDevice(&device); //this will change the valeu of device \n",
        "  printf(\"Device # = %d\\n\", device);\n",
        " // cudaMemPrefetchAsync(in, ARRAY_BYTES,device,NULL);\n",
        " //Advise GPU that the 'in' array stays in the host(CPU) memory -- \"copy and paste\"\n",
        "  cudaMemAdvise(in, ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "  // Asynchronously transfer data ahead of time from GPU memory back to the host memory\n",
        "  cudaMemPrefetchAsync(in, ARRAY_BYTES, cudaCpuDeviceId, NULL); // NULL means run one stream\n",
        " //Asynchronously transfer data ahead of time to the GPU memory -- \"cut and paste\"\n",
        "  cudaMemPrefetchAsync(out, ARRAY_BYTES,device,NULL); //null means run one stream\n",
        "\n",
        "  //initialize data\n",
        "  for (int i=0; i<ARRAY_SIZE; i++)\n",
        "    in[i] = float(i);\n",
        "\n",
        "  // -- Prefetch data part #2--\n",
        "  //Advise GPU that the 'in' array is read-only\n",
        "  cudaMemAdvise(in, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "  //Copy and paste data from host memory to GPU memory\n",
        "  cudaMemPrefetchAsync(in, ARRAY_BYTES, device, NULL); //NULL means run one stream\n",
        "\n",
        "\n",
        "  //start here\n",
        "  int numThreads = 1024;\n",
        "  int numBlocks = (ARRAY_SIZE+numThreads-1) / numThreads;\n",
        "  for(int i=0; i<runs; i++){\n",
        "    conv<<<numBlocks, numThreads>>>(ARRAY_SIZE,out,in);\n",
        "  }\n",
        "\n",
        "  printf(\"numThreads = %d, numBlocks = %d\\n\", numThreads, numBlocks); \n",
        "  //wait for the GPU to completerun/execution\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  //Prefetch data #3 again to omit the instance of PAGEFAULT\n",
        " // cudaMemPrefetchAsync(in, ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
        "  cudaMemPrefetchAsync(out, ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
        "\n",
        "  //check for errors\n",
        "  unsigned int err_count = 0;\n",
        "  for(int i=0; i<ARRAY_SIZE-2; i++){\n",
        "    if((in[i]+in[i+1]+in[i+2])/3.0f != out[i])\n",
        "      err_count++;\n",
        "  }\n",
        "  printf(\"\\n Error count (CUDA program): %d\\n\", err_count);\n",
        "\n",
        "\n",
        "  //free memory\n",
        "  cudaFree(in);\n",
        "  cudaFree(out);\n",
        "  \n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "Flv82WEBZnnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc CUDA_3c.cu -o CUDA_3c\n",
        "nvprof ./CUDA_3c"
      ],
      "metadata": {
        "id": "Bj4QibQjBA8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector Size: `2^22`"
      ],
      "metadata": {
        "id": "YgD6U81BZzXp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of Threads: `256`"
      ],
      "metadata": {
        "id": "gbXkVNv9ZzXv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkKe5TH1ZzXw"
      },
      "outputs": [],
      "source": [
        "%%writefile CUDA_3d.cu\n",
        "\n",
        "//with maximum pre-fetching \n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "//CUDA square kernel\n",
        "__global__\n",
        "void conv(int n, float* d_out, float* d_in){\n",
        "  int index = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x*gridDim.x;\n",
        "  for(int i=index; i<n-2; i+=stride){\n",
        "    d_out[i] = (d_in[i] + d_in[i+1] + d_in[i+2])/3.0f;\n",
        "  }\n",
        "\n",
        "}\n",
        "\n",
        "int main(){\n",
        "  \n",
        "  const unsigned int ARRAY_SIZE = 1<<22; \n",
        "  const unsigned ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
        "  const int runs = 30;\n",
        "\n",
        "  //declary ARRAY\n",
        "  float *in, *out;\n",
        "  cudaMallocManaged(&in, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&out, ARRAY_BYTES);\n",
        "\n",
        "// --- prefetch the data #1---- //\n",
        "  int device = -1; //garbage value (it means NO GPU found)\n",
        "  cudaGetDevice(&device); //this will change the valeu of device \n",
        "  printf(\"Device # = %d\\n\", device);\n",
        " // cudaMemPrefetchAsync(in, ARRAY_BYTES,device,NULL);\n",
        " //Advise GPU that the 'in' array stays in the host(CPU) memory -- \"copy and paste\"\n",
        "  cudaMemAdvise(in, ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "  // Asynchronously transfer data ahead of time from GPU memory back to the host memory\n",
        "  cudaMemPrefetchAsync(in, ARRAY_BYTES, cudaCpuDeviceId, NULL); // NULL means run one stream\n",
        " //Asynchronously transfer data ahead of time to the GPU memory -- \"cut and paste\"\n",
        "  cudaMemPrefetchAsync(out, ARRAY_BYTES,device,NULL); //null means run one stream\n",
        "\n",
        "  //initialize data\n",
        "  for (int i=0; i<ARRAY_SIZE; i++)\n",
        "    in[i] = float(i);\n",
        "\n",
        "  // -- Prefetch data part #2--\n",
        "  //Advise GPU that the 'in' array is read-only\n",
        "  cudaMemAdvise(in, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "  //Copy and paste data from host memory to GPU memory\n",
        "  cudaMemPrefetchAsync(in, ARRAY_BYTES, device, NULL); //NULL means run one stream\n",
        "\n",
        "\n",
        "  //start here\n",
        "  int numThreads = 256;\n",
        "  int numBlocks = (ARRAY_SIZE+numThreads-1) / numThreads;\n",
        "  for(int i=0; i<runs; i++){\n",
        "    conv<<<numBlocks, numThreads>>>(ARRAY_SIZE,out,in);\n",
        "  }\n",
        "\n",
        "  printf(\"numThreads = %d, numBlocks = %d\\n\", numThreads, numBlocks); \n",
        "  //wait for the GPU to completerun/execution\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  //Prefetch data #3 again to omit the instance of PAGEFAULT\n",
        " // cudaMemPrefetchAsync(in, ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
        "  cudaMemPrefetchAsync(out, ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
        "\n",
        "  //check for errors\n",
        "  unsigned int err_count = 0;\n",
        "  for(int i=0; i<ARRAY_SIZE-2; i++){\n",
        "    if((in[i]+in[i+1]+in[i+2])/3.0f != out[i])\n",
        "      err_count++;\n",
        "  }\n",
        "  printf(\"\\n Error count (CUDA program): %d\\n\", err_count);\n",
        "\n",
        "\n",
        "  //free memory\n",
        "  cudaFree(in);\n",
        "  cudaFree(out);\n",
        "  \n",
        "  return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc CUDA_3d.cu -o CUDA_3d\n",
        "nvprof ./CUDA_3d"
      ],
      "metadata": {
        "id": "CIfoFEslBD3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of Threads: `512`"
      ],
      "metadata": {
        "id": "5far88Q7ZzXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile CUDA_3e.cu\n",
        "\n",
        "//with maximum pre-fetching \n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "//CUDA square kernel\n",
        "__global__\n",
        "void conv(int n, float* d_out, float* d_in){\n",
        "  int index = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x*gridDim.x;\n",
        "  for(int i=index; i<n-2; i+=stride){\n",
        "    d_out[i] = (d_in[i] + d_in[i+1] + d_in[i+2])/3.0f;\n",
        "  }\n",
        "\n",
        "}\n",
        "\n",
        "int main(){\n",
        "  \n",
        "  const unsigned int ARRAY_SIZE = 1<<22; \n",
        "  const unsigned ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
        "  const int runs = 30;\n",
        "\n",
        "  //declary ARRAY\n",
        "  float *in, *out;\n",
        "  cudaMallocManaged(&in, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&out, ARRAY_BYTES);\n",
        "\n",
        "// --- prefetch the data #1---- //\n",
        "  int device = -1; //garbage value (it means NO GPU found)\n",
        "  cudaGetDevice(&device); //this will change the valeu of device \n",
        "  printf(\"Device # = %d\\n\", device);\n",
        " // cudaMemPrefetchAsync(in, ARRAY_BYTES,device,NULL);\n",
        " //Advise GPU that the 'in' array stays in the host(CPU) memory -- \"copy and paste\"\n",
        "  cudaMemAdvise(in, ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "  // Asynchronously transfer data ahead of time from GPU memory back to the host memory\n",
        "  cudaMemPrefetchAsync(in, ARRAY_BYTES, cudaCpuDeviceId, NULL); // NULL means run one stream\n",
        " //Asynchronously transfer data ahead of time to the GPU memory -- \"cut and paste\"\n",
        "  cudaMemPrefetchAsync(out, ARRAY_BYTES,device,NULL); //null means run one stream\n",
        "\n",
        "  //initialize data\n",
        "  for (int i=0; i<ARRAY_SIZE; i++)\n",
        "    in[i] = float(i);\n",
        "\n",
        "  // -- Prefetch data part #2--\n",
        "  //Advise GPU that the 'in' array is read-only\n",
        "  cudaMemAdvise(in, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "  //Copy and paste data from host memory to GPU memory\n",
        "  cudaMemPrefetchAsync(in, ARRAY_BYTES, device, NULL); //NULL means run one stream\n",
        "\n",
        "\n",
        "  //start here\n",
        "  int numThreads = 512;\n",
        "  int numBlocks = (ARRAY_SIZE+numThreads-1) / numThreads;\n",
        "  for(int i=0; i<runs; i++){\n",
        "    conv<<<numBlocks, numThreads>>>(ARRAY_SIZE,out,in);\n",
        "  }\n",
        "\n",
        "  printf(\"numThreads = %d, numBlocks = %d\\n\", numThreads, numBlocks); \n",
        "  //wait for the GPU to completerun/execution\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  //Prefetch data #3 again to omit the instance of PAGEFAULT\n",
        " // cudaMemPrefetchAsync(in, ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
        "  cudaMemPrefetchAsync(out, ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
        "\n",
        "  //check for errors\n",
        "  unsigned int err_count = 0;\n",
        "  for(int i=0; i<ARRAY_SIZE-2; i++){\n",
        "    if((in[i]+in[i+1]+in[i+2])/3.0f != out[i])\n",
        "      err_count++;\n",
        "  }\n",
        "  printf(\"\\n Error count (CUDA program): %d\\n\", err_count);\n",
        "\n",
        "\n",
        "  //free memory\n",
        "  cudaFree(in);\n",
        "  cudaFree(out);\n",
        "  \n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "6snbdrsBZzXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc CUDA_3e.cu -o CUDA_3e\n",
        "nvprof ./CUDA_3e"
      ],
      "metadata": {
        "id": "b7j2cTc8BF4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of Threads: `1024`"
      ],
      "metadata": {
        "id": "75oUCMjYZzXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile CUDA_3f.cu\n",
        "\n",
        "//with maximum pre-fetching \n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "//CUDA square kernel\n",
        "__global__\n",
        "void conv(int n, float* d_out, float* d_in){\n",
        "  int index = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x*gridDim.x;\n",
        "  for(int i=index; i<n-2; i+=stride){\n",
        "    d_out[i] = (d_in[i] + d_in[i+1] + d_in[i+2])/3.0f;\n",
        "  }\n",
        "\n",
        "}\n",
        "\n",
        "int main(){\n",
        "  \n",
        "  const unsigned int ARRAY_SIZE = 1<<22; \n",
        "  const unsigned ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
        "  const int runs = 30;\n",
        "\n",
        "  //declary ARRAY\n",
        "  float *in, *out;\n",
        "  cudaMallocManaged(&in, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&out, ARRAY_BYTES);\n",
        "\n",
        "// --- prefetch the data #1---- //\n",
        "  int device = -1; //garbage value (it means NO GPU found)\n",
        "  cudaGetDevice(&device); //this will change the valeu of device \n",
        "  printf(\"Device # = %d\\n\", device);\n",
        " // cudaMemPrefetchAsync(in, ARRAY_BYTES,device,NULL);\n",
        " //Advise GPU that the 'in' array stays in the host(CPU) memory -- \"copy and paste\"\n",
        "  cudaMemAdvise(in, ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "  // Asynchronously transfer data ahead of time from GPU memory back to the host memory\n",
        "  cudaMemPrefetchAsync(in, ARRAY_BYTES, cudaCpuDeviceId, NULL); // NULL means run one stream\n",
        " //Asynchronously transfer data ahead of time to the GPU memory -- \"cut and paste\"\n",
        "  cudaMemPrefetchAsync(out, ARRAY_BYTES,device,NULL); //null means run one stream\n",
        "\n",
        "  //initialize data\n",
        "  for (int i=0; i<ARRAY_SIZE; i++)\n",
        "    in[i] = float(i);\n",
        "\n",
        "  // -- Prefetch data part #2--\n",
        "  //Advise GPU that the 'in' array is read-only\n",
        "  cudaMemAdvise(in, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "  //Copy and paste data from host memory to GPU memory\n",
        "  cudaMemPrefetchAsync(in, ARRAY_BYTES, device, NULL); //NULL means run one stream\n",
        "\n",
        "\n",
        "  //start here\n",
        "  int numThreads = 1024;\n",
        "  int numBlocks = (ARRAY_SIZE+numThreads-1) / numThreads;\n",
        "  for(int i=0; i<runs; i++){\n",
        "    conv<<<numBlocks, numThreads>>>(ARRAY_SIZE,out,in);\n",
        "  }\n",
        "\n",
        "  printf(\"numThreads = %d, numBlocks = %d\\n\", numThreads, numBlocks); \n",
        "  //wait for the GPU to completerun/execution\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  //Prefetch data #3 again to omit the instance of PAGEFAULT\n",
        " // cudaMemPrefetchAsync(in, ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
        "  cudaMemPrefetchAsync(out, ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
        "\n",
        "  //check for errors\n",
        "  unsigned int err_count = 0;\n",
        "  for(int i=0; i<ARRAY_SIZE-2; i++){\n",
        "    if((in[i]+in[i+1]+in[i+2])/3.0f != out[i])\n",
        "      err_count++;\n",
        "  }\n",
        "  printf(\"\\n Error count (CUDA program): %d\\n\", err_count);\n",
        "\n",
        "\n",
        "  //free memory\n",
        "  cudaFree(in);\n",
        "  cudaFree(out);\n",
        "  \n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "zSby9WnDZzXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc CUDA_3f.cu -o CUDA_3f\n",
        "nvprof ./CUDA_3f"
      ],
      "metadata": {
        "id": "PUYTE3aBBHqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector Size: `2^24`"
      ],
      "metadata": {
        "id": "9NkauBkFZ2Rm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of Threads: `256`"
      ],
      "metadata": {
        "id": "AxSPYwF9Z2Rs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ibw4jJGlZ2Rt"
      },
      "outputs": [],
      "source": [
        "%%writefile CUDA_3g.cu\n",
        "\n",
        "//with maximum pre-fetching \n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "//CUDA square kernel\n",
        "__global__\n",
        "void conv(int n, float* d_out, float* d_in){\n",
        "  int index = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x*gridDim.x;\n",
        "  for(int i=index; i<n-2; i+=stride){\n",
        "    d_out[i] = (d_in[i] + d_in[i+1] + d_in[i+2])/3.0f;\n",
        "  }\n",
        "\n",
        "}\n",
        "\n",
        "int main(){\n",
        "  \n",
        "  const unsigned int ARRAY_SIZE = 1<<24; \n",
        "  const unsigned ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
        "  const int runs = 30;\n",
        "\n",
        "  //declary ARRAY\n",
        "  float *in, *out;\n",
        "  cudaMallocManaged(&in, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&out, ARRAY_BYTES);\n",
        "\n",
        "// --- prefetch the data #1---- //\n",
        "  int device = -1; //garbage value (it means NO GPU found)\n",
        "  cudaGetDevice(&device); //this will change the valeu of device \n",
        "  printf(\"Device # = %d\\n\", device);\n",
        " // cudaMemPrefetchAsync(in, ARRAY_BYTES,device,NULL);\n",
        " //Advise GPU that the 'in' array stays in the host(CPU) memory -- \"copy and paste\"\n",
        "  cudaMemAdvise(in, ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "  // Asynchronously transfer data ahead of time from GPU memory back to the host memory\n",
        "  cudaMemPrefetchAsync(in, ARRAY_BYTES, cudaCpuDeviceId, NULL); // NULL means run one stream\n",
        " //Asynchronously transfer data ahead of time to the GPU memory -- \"cut and paste\"\n",
        "  cudaMemPrefetchAsync(out, ARRAY_BYTES,device,NULL); //null means run one stream\n",
        "\n",
        "  //initialize data\n",
        "  for (int i=0; i<ARRAY_SIZE; i++)\n",
        "    in[i] = float(i);\n",
        "\n",
        "  // -- Prefetch data part #2--\n",
        "  //Advise GPU that the 'in' array is read-only\n",
        "  cudaMemAdvise(in, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "  //Copy and paste data from host memory to GPU memory\n",
        "  cudaMemPrefetchAsync(in, ARRAY_BYTES, device, NULL); //NULL means run one stream\n",
        "\n",
        "\n",
        "  //start here\n",
        "  int numThreads = 256;\n",
        "  int numBlocks = (ARRAY_SIZE+numThreads-1) / numThreads;\n",
        "  for(int i=0; i<runs; i++){\n",
        "    conv<<<numBlocks, numThreads>>>(ARRAY_SIZE,out,in);\n",
        "  }\n",
        "\n",
        "  printf(\"numThreads = %d, numBlocks = %d\\n\", numThreads, numBlocks); \n",
        "  //wait for the GPU to completerun/execution\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  //Prefetch data #3 again to omit the instance of PAGEFAULT\n",
        " // cudaMemPrefetchAsync(in, ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
        "  cudaMemPrefetchAsync(out, ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
        "\n",
        "  //check for errors\n",
        "  unsigned int err_count = 0;\n",
        "  for(int i=0; i<ARRAY_SIZE-2; i++){\n",
        "    if((in[i]+in[i+1]+in[i+2])/3.0f != out[i])\n",
        "      err_count++;\n",
        "  }\n",
        "  printf(\"\\n Error count (CUDA program): %d\\n\", err_count);\n",
        "\n",
        "\n",
        "  //free memory\n",
        "  cudaFree(in);\n",
        "  cudaFree(out);\n",
        "  \n",
        "  return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc CUDA_3g.cu -o CUDA_3g\n",
        "nvprof ./CUDA_3g"
      ],
      "metadata": {
        "id": "xqTpnNjVBJtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of Threads: `512`"
      ],
      "metadata": {
        "id": "H0OE8mUlZ2Rt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile CUDA_3h.cu\n",
        "\n",
        "//with maximum pre-fetching \n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "//CUDA square kernel\n",
        "__global__\n",
        "void conv(int n, float* d_out, float* d_in){\n",
        "  int index = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x*gridDim.x;\n",
        "  for(int i=index; i<n-2; i+=stride){\n",
        "    d_out[i] = (d_in[i] + d_in[i+1] + d_in[i+2])/3.0f;\n",
        "  }\n",
        "\n",
        "}\n",
        "\n",
        "int main(){\n",
        "  \n",
        "  const unsigned int ARRAY_SIZE = 1<<24; \n",
        "  const unsigned ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
        "  const int runs = 30;\n",
        "\n",
        "  //declary ARRAY\n",
        "  float *in, *out;\n",
        "  cudaMallocManaged(&in, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&out, ARRAY_BYTES);\n",
        "\n",
        "// --- prefetch the data #1---- //\n",
        "  int device = -1; //garbage value (it means NO GPU found)\n",
        "  cudaGetDevice(&device); //this will change the valeu of device \n",
        "  printf(\"Device # = %d\\n\", device);\n",
        " // cudaMemPrefetchAsync(in, ARRAY_BYTES,device,NULL);\n",
        " //Advise GPU that the 'in' array stays in the host(CPU) memory -- \"copy and paste\"\n",
        "  cudaMemAdvise(in, ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "  // Asynchronously transfer data ahead of time from GPU memory back to the host memory\n",
        "  cudaMemPrefetchAsync(in, ARRAY_BYTES, cudaCpuDeviceId, NULL); // NULL means run one stream\n",
        " //Asynchronously transfer data ahead of time to the GPU memory -- \"cut and paste\"\n",
        "  cudaMemPrefetchAsync(out, ARRAY_BYTES,device,NULL); //null means run one stream\n",
        "\n",
        "  //initialize data\n",
        "  for (int i=0; i<ARRAY_SIZE; i++)\n",
        "    in[i] = float(i);\n",
        "\n",
        "  // -- Prefetch data part #2--\n",
        "  //Advise GPU that the 'in' array is read-only\n",
        "  cudaMemAdvise(in, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "  //Copy and paste data from host memory to GPU memory\n",
        "  cudaMemPrefetchAsync(in, ARRAY_BYTES, device, NULL); //NULL means run one stream\n",
        "\n",
        "\n",
        "  //start here\n",
        "  int numThreads = 512;\n",
        "  int numBlocks = (ARRAY_SIZE+numThreads-1) / numThreads;\n",
        "  for(int i=0; i<runs; i++){\n",
        "    conv<<<numBlocks, numThreads>>>(ARRAY_SIZE,out,in);\n",
        "  }\n",
        "\n",
        "  printf(\"numThreads = %d, numBlocks = %d\\n\", numThreads, numBlocks); \n",
        "  //wait for the GPU to completerun/execution\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  //Prefetch data #3 again to omit the instance of PAGEFAULT\n",
        " // cudaMemPrefetchAsync(in, ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
        "  cudaMemPrefetchAsync(out, ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
        "\n",
        "  //check for errors\n",
        "  unsigned int err_count = 0;\n",
        "  for(int i=0; i<ARRAY_SIZE-2; i++){\n",
        "    if((in[i]+in[i+1]+in[i+2])/3.0f != out[i])\n",
        "      err_count++;\n",
        "  }\n",
        "  printf(\"\\n Error count (CUDA program): %d\\n\", err_count);\n",
        "\n",
        "\n",
        "  //free memory\n",
        "  cudaFree(in);\n",
        "  cudaFree(out);\n",
        "  \n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "Q9lTiclaZ2Rt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc CUDA_3h.cu -o CUDA_3h\n",
        "nvprof ./CUDA_3h"
      ],
      "metadata": {
        "id": "H6AeMJshBL6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of Threads: `1024`"
      ],
      "metadata": {
        "id": "aIfyhtb8Z2Rt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile CUDA_3i.cu\n",
        "\n",
        "//with maximum pre-fetching \n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "//CUDA square kernel\n",
        "__global__\n",
        "void conv(int n, float* d_out, float* d_in){\n",
        "  int index = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x*gridDim.x;\n",
        "  for(int i=index; i<n-2; i+=stride){\n",
        "    d_out[i] = (d_in[i] + d_in[i+1] + d_in[i+2])/3.0f;\n",
        "  }\n",
        "\n",
        "}\n",
        "\n",
        "int main(){\n",
        "  \n",
        "  const unsigned int ARRAY_SIZE = 1<<24; \n",
        "  const unsigned ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
        "  const int runs = 30;\n",
        "\n",
        "  //declary ARRAY\n",
        "  float *in, *out;\n",
        "  cudaMallocManaged(&in, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&out, ARRAY_BYTES);\n",
        "\n",
        "// --- prefetch the data #1---- //\n",
        "  int device = -1; //garbage value (it means NO GPU found)\n",
        "  cudaGetDevice(&device); //this will change the valeu of device \n",
        "  printf(\"Device # = %d\\n\", device);\n",
        " // cudaMemPrefetchAsync(in, ARRAY_BYTES,device,NULL);\n",
        " //Advise GPU that the 'in' array stays in the host(CPU) memory -- \"copy and paste\"\n",
        "  cudaMemAdvise(in, ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "  // Asynchronously transfer data ahead of time from GPU memory back to the host memory\n",
        "  cudaMemPrefetchAsync(in, ARRAY_BYTES, cudaCpuDeviceId, NULL); // NULL means run one stream\n",
        " //Asynchronously transfer data ahead of time to the GPU memory -- \"cut and paste\"\n",
        "  cudaMemPrefetchAsync(out, ARRAY_BYTES,device,NULL); //null means run one stream\n",
        "\n",
        "  //initialize data\n",
        "  for (int i=0; i<ARRAY_SIZE; i++)\n",
        "    in[i] = float(i);\n",
        "\n",
        "  // -- Prefetch data part #2--\n",
        "  //Advise GPU that the 'in' array is read-only\n",
        "  cudaMemAdvise(in, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "  //Copy and paste data from host memory to GPU memory\n",
        "  cudaMemPrefetchAsync(in, ARRAY_BYTES, device, NULL); //NULL means run one stream\n",
        "\n",
        "\n",
        "  //start here\n",
        "  int numThreads = 1024;\n",
        "  int numBlocks = (ARRAY_SIZE+numThreads-1) / numThreads;\n",
        "  for(int i=0; i<runs; i++){\n",
        "    conv<<<numBlocks, numThreads>>>(ARRAY_SIZE,out,in);\n",
        "  }\n",
        "\n",
        "  printf(\"numThreads = %d, numBlocks = %d\\n\", numThreads, numBlocks); \n",
        "  //wait for the GPU to completerun/execution\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  //Prefetch data #3 again to omit the instance of PAGEFAULT\n",
        " // cudaMemPrefetchAsync(in, ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
        "  cudaMemPrefetchAsync(out, ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
        "\n",
        "  //check for errors\n",
        "  unsigned int err_count = 0;\n",
        "  for(int i=0; i<ARRAY_SIZE-2; i++){\n",
        "    if((in[i]+in[i+1]+in[i+2])/3.0f != out[i])\n",
        "      err_count++;\n",
        "  }\n",
        "  printf(\"\\n Error count (CUDA program): %d\\n\", err_count);\n",
        "\n",
        "\n",
        "  //free memory\n",
        "  cudaFree(in);\n",
        "  cudaFree(out);\n",
        "  \n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "KtI_HopRZ2Rt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc CUDA_3i.cu -o CUDA_3i\n",
        "nvprof ./CUDA_3i"
      ],
      "metadata": {
        "id": "52Dz8sd8BNyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYXNHeCTxcQK"
      },
      "source": [
        "#IMPLEMENTATION #4: Data Transfer or Initialization as a CUDA Kernel"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector Size: `2^20`"
      ],
      "metadata": {
        "id": "WtVIUdVuZ35q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of Threads: `256`"
      ],
      "metadata": {
        "id": "80wCyjn7Z7Gp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANB7ZXmmxiAY"
      },
      "outputs": [],
      "source": [
        "%%writefile cuda_4_2r20_256.cu\n",
        "// Data Transfer method: Initialization as a CUDA Kernel\n",
        "// Vector size: 2^20\n",
        "// Number of Threads: 256\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "\n",
        "// Initialize data in CUDA kernel\n",
        "__global__\n",
        "void init(int n, float *out, float *in) {\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < n; i += stride) {\n",
        "    in[i] = float(i);\n",
        "    out[i] = float(0);\n",
        "  }\n",
        "}\n",
        "\n",
        "// 1-Dimensional convolution\n",
        "__global__\n",
        "void conv_1d(int n, float *out, float *in) {\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < n - 2; i += stride) {\n",
        "    out[i] = (in[i] + in[i+1] + in[i+2]) / 3.0f;\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "int main() {\n",
        "  // Initialize specs for program\n",
        "  const unsigned int RUNS = 30;\n",
        "  const unsigned int VECTOR_SIZE = 1 << 20;\n",
        "  const unsigned int THREAD_NUM = 256; \n",
        "  const unsigned int VECTOR_BYTES = VECTOR_SIZE * sizeof(float);\n",
        "  int numBlocks = (VECTOR_SIZE + THREAD_NUM - 1) / THREAD_NUM;\n",
        "\n",
        "  printf(\"\\n%s\\n\\n%s\\n%s: %u\\n%s: %d\\n%s: %d\\n\\n\",\n",
        "    \"#=== GPU-CPU Memory Transfer ===#\",\n",
        "    \"-- 1-D Convolution --\",\n",
        "    \"Vector size\", VECTOR_SIZE,\n",
        "    \"Number of threads\", THREAD_NUM,\n",
        "    \"Number of blocks\", numBlocks\n",
        "  );\n",
        "\n",
        "  // Allocate memory\n",
        "  float *in, *out;\n",
        "  cudaMallocManaged(&in, VECTOR_BYTES);\n",
        "  cudaMallocManaged(&out, VECTOR_BYTES);\n",
        "\n",
        "  // Initialize data in CUDA kernel\n",
        "  init<<<numBlocks, THREAD_NUM>>>(VECTOR_SIZE, out, in);\n",
        "\n",
        "  // Run kernel for 1-D convolution\n",
        "  for(int i = 0; i < RUNS; i++)\n",
        "    conv_1d<<<numBlocks, THREAD_NUM>>>(VECTOR_SIZE, out, in);\n",
        "\n",
        "  // Wait for GPU to finish before accessing on host\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  // Check for errors\n",
        "  int errorCount = 0;\n",
        "  unsigned int max = VECTOR_SIZE - 2;\n",
        "  for(int i = 0; i < max; i++) {\n",
        "    if((in[i] + in[i+1] + in[i+2]) / 3.0f != out[i])\n",
        "      errorCount++;\n",
        "  }\n",
        "  printf(\"Error count: %d\\n\", errorCount);\n",
        "\n",
        "  // Free memory\n",
        "  cudaFree(in);\n",
        "  cudaFree(out);\n",
        "\n",
        "  return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc cuda_4_2r20_256.cu -o cuda_4_2r20_256"
      ],
      "metadata": {
        "id": "hTX5M9yRg6Dm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvprof ./cuda_4_2r20_256"
      ],
      "metadata": {
        "id": "boocBq5-g_B2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of Threads: `512`"
      ],
      "metadata": {
        "id": "9OuR3ruYaEhP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cuda_4_2r20_512.cu\n",
        "// Data Transfer method: Initialization as a CUDA Kernel\n",
        "// Vector size: 2^20\n",
        "// Number of Threads: 512\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "\n",
        "// Initialize data in CUDA kernel\n",
        "__global__\n",
        "void init(int n, float *out, float *in) {\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < n; i += stride) {\n",
        "    in[i] = float(i);\n",
        "    out[i] = float(0);\n",
        "  }\n",
        "}\n",
        "\n",
        "// 1-Dimensional convolution\n",
        "__global__\n",
        "void conv_1d(int n, float *out, float *in) {\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < n - 2; i += stride) {\n",
        "    out[i] = (in[i] + in[i+1] + in[i+2]) / 3.0f;\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "int main() {\n",
        "  // Initialize specs for program\n",
        "  const unsigned int RUNS = 30;\n",
        "  const unsigned int VECTOR_SIZE = 1 << 20;\n",
        "  const unsigned int THREAD_NUM = 512;\n",
        "  const unsigned int VECTOR_BYTES = VECTOR_SIZE * sizeof(float);\n",
        "  int numBlocks = (VECTOR_SIZE + THREAD_NUM - 1) / THREAD_NUM;\n",
        "\n",
        "  printf(\"\\n%s\\n\\n%s\\n%s: %u\\n%s: %d\\n%s: %d\\n\\n\",\n",
        "    \"#=== GPU-CPU Memory Transfer ===#\",\n",
        "    \"-- 1-D Convolution --\",\n",
        "    \"Vector size\", VECTOR_SIZE,\n",
        "    \"Number of threads\", THREAD_NUM,\n",
        "    \"Number of blocks\", numBlocks\n",
        "  );\n",
        "\n",
        "  // Allocate memory\n",
        "  float *in, *out;\n",
        "  cudaMallocManaged(&in, VECTOR_BYTES);\n",
        "  cudaMallocManaged(&out, VECTOR_BYTES);\n",
        "\n",
        "  // Initialize data in CUDA kernel\n",
        "  init<<<numBlocks, THREAD_NUM>>>(VECTOR_SIZE, out, in);\n",
        "\n",
        "  // Run kernel for 1-D convolution\n",
        "  for(int i = 0; i < RUNS; i++)\n",
        "    conv_1d<<<numBlocks, THREAD_NUM>>>(VECTOR_SIZE, out, in);\n",
        "\n",
        "  // Wait for GPU to finish before accessing on host\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  // Check for errors\n",
        "  int errorCount = 0;\n",
        "  unsigned int max = VECTOR_SIZE - 2;\n",
        "  for(int i = 0; i < max; i++) {\n",
        "    if((in[i] + in[i+1] + in[i+2]) / 3.0f != out[i])\n",
        "      errorCount++;\n",
        "  }\n",
        "  printf(\"Error count: %d\\n\", errorCount);\n",
        "\n",
        "  // Free memory\n",
        "  cudaFree(in);\n",
        "  cudaFree(out);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "hfzeO5uSaEhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc cuda_4_2r20_512.cu -o cuda_4_2r20_512"
      ],
      "metadata": {
        "id": "cbJRXHap1fCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvprof ./cuda_4_2r20_512"
      ],
      "metadata": {
        "id": "K322gq-11fCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of Threads: `1024`"
      ],
      "metadata": {
        "id": "aSxNfU2NaEiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cuda_4_2r20_1024.cu\n",
        "// Data Transfer method: Initialization as a CUDA Kernel\n",
        "// Vector size: 2^20\n",
        "// Number of Threads: 1024\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "\n",
        "// Initialize data in CUDA kernel\n",
        "__global__\n",
        "void init(int n, float *out, float *in) {\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < n; i += stride) {\n",
        "    in[i] = float(i);\n",
        "    out[i] = float(0);\n",
        "  }\n",
        "}\n",
        "\n",
        "// 1-Dimensional convolution\n",
        "__global__\n",
        "void conv_1d(int n, float *out, float *in) {\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < n - 2; i += stride) {\n",
        "    out[i] = (in[i] + in[i+1] + in[i+2]) / 3.0f;\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "int main() {\n",
        "  // Initialize specs for program\n",
        "  const unsigned int RUNS = 30;\n",
        "  const unsigned int VECTOR_SIZE = 1 << 20;\n",
        "  const unsigned int THREAD_NUM = 1024;\n",
        "  const unsigned int VECTOR_BYTES = VECTOR_SIZE * sizeof(float);\n",
        "  int numBlocks = (VECTOR_SIZE + THREAD_NUM - 1) / THREAD_NUM;\n",
        "\n",
        "  printf(\"\\n%s\\n\\n%s\\n%s: %u\\n%s: %d\\n%s: %d\\n\\n\",\n",
        "    \"#=== GPU-CPU Memory Transfer ===#\",\n",
        "    \"-- 1-D Convolution --\",\n",
        "    \"Vector size\", VECTOR_SIZE,\n",
        "    \"Number of threads\", THREAD_NUM,\n",
        "    \"Number of blocks\", numBlocks\n",
        "  );\n",
        "\n",
        "  // Allocate memory\n",
        "  float *in, *out;\n",
        "  cudaMallocManaged(&in, VECTOR_BYTES);\n",
        "  cudaMallocManaged(&out, VECTOR_BYTES);\n",
        "\n",
        "  // Initialize data in CUDA kernel\n",
        "  init<<<numBlocks, THREAD_NUM>>>(VECTOR_SIZE, out, in);\n",
        "\n",
        "  // Run kernel for 1-D convolution\n",
        "  for(int i = 0; i < RUNS; i++)\n",
        "    conv_1d<<<numBlocks, THREAD_NUM>>>(VECTOR_SIZE, out, in);\n",
        "\n",
        "  // Wait for GPU to finish before accessing on host\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  // Check for errors\n",
        "  int errorCount = 0;\n",
        "  unsigned int max = VECTOR_SIZE - 2;\n",
        "  for(int i = 0; i < max; i++) {\n",
        "    if((in[i] + in[i+1] + in[i+2]) / 3.0f != out[i])\n",
        "      errorCount++;\n",
        "  }\n",
        "  printf(\"Error count: %d\\n\", errorCount);\n",
        "\n",
        "  // Free memory\n",
        "  cudaFree(in);\n",
        "  cudaFree(out);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "DJ899W4ZaEiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc cuda_4_2r20_1024.cu -o cuda_4_2r20_1024"
      ],
      "metadata": {
        "id": "wHvLm62a2LG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvprof ./cuda_4_2r20_1024"
      ],
      "metadata": {
        "id": "L5X-U0XQ2LHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector Size: `2^22`"
      ],
      "metadata": {
        "id": "dTfpYeKPabMw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of Threads: `256`"
      ],
      "metadata": {
        "id": "e71ZEDAsabM3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNUwhxZyabM3"
      },
      "outputs": [],
      "source": [
        "%%writefile cuda_4_2r22_256.cu\n",
        "// Data Transfer method: Initialization as a CUDA Kernel\n",
        "// Vector size: 2^22\n",
        "// Number of Threads: 256\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "\n",
        "// Initialize data in CUDA kernel\n",
        "__global__\n",
        "void init(int n, float *out, float *in) {\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < n; i += stride) {\n",
        "    in[i] = float(i);\n",
        "    out[i] = float(0);\n",
        "  }\n",
        "}\n",
        "\n",
        "// 1-Dimensional convolution\n",
        "__global__\n",
        "void conv_1d(int n, float *out, float *in) {\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < n - 2; i += stride) {\n",
        "    out[i] = (in[i] + in[i+1] + in[i+2]) / 3.0f;\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "int main() {\n",
        "  // Initialize specs for program\n",
        "  const unsigned int RUNS = 30;\n",
        "  const unsigned int VECTOR_SIZE = 1 << 22;\n",
        "  const unsigned int THREAD_NUM = 256;\n",
        "  const unsigned int VECTOR_BYTES = VECTOR_SIZE * sizeof(float);\n",
        "  int numBlocks = (VECTOR_SIZE + THREAD_NUM - 1) / THREAD_NUM;\n",
        "\n",
        "  printf(\"\\n%s\\n\\n%s\\n%s: %u\\n%s: %d\\n%s: %d\\n\\n\",\n",
        "    \"#=== GPU-CPU Memory Transfer ===#\",\n",
        "    \"-- 1-D Convolution --\",\n",
        "    \"Vector size\", VECTOR_SIZE,\n",
        "    \"Number of threads\", THREAD_NUM,\n",
        "    \"Number of blocks\", numBlocks\n",
        "  );\n",
        "\n",
        "  // Allocate memory\n",
        "  float *in, *out;\n",
        "  cudaMallocManaged(&in, VECTOR_BYTES);\n",
        "  cudaMallocManaged(&out, VECTOR_BYTES);\n",
        "\n",
        "  // Initialize data in CUDA kernel\n",
        "  init<<<numBlocks, THREAD_NUM>>>(VECTOR_SIZE, out, in);\n",
        "\n",
        "  // Run kernel for 1-D convolution\n",
        "  for(int i = 0; i < RUNS; i++)\n",
        "    conv_1d<<<numBlocks, THREAD_NUM>>>(VECTOR_SIZE, out, in);\n",
        "\n",
        "  // Wait for GPU to finish before accessing on host\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  // Check for errors\n",
        "  int errorCount = 0;\n",
        "  unsigned int max = VECTOR_SIZE - 2;\n",
        "  for(int i = 0; i < max; i++) {\n",
        "    if((in[i] + in[i+1] + in[i+2]) / 3.0f != out[i])\n",
        "      errorCount++;\n",
        "  }\n",
        "  printf(\"Error count: %d\\n\", errorCount);\n",
        "\n",
        "  // Free memory\n",
        "  cudaFree(in);\n",
        "  cudaFree(out);\n",
        "\n",
        "  return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc cuda_4_2r22_256.cu -o cuda_4_2r22_256"
      ],
      "metadata": {
        "id": "1yhu3hMQ2et9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvprof ./cuda_4_2r22_256"
      ],
      "metadata": {
        "id": "7Rfn_J6B2euE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of Threads: `512`"
      ],
      "metadata": {
        "id": "lqotuf6CabM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cuda_4_2r22_512.cu\n",
        "// Data Transfer method: Initialization as a CUDA Kernel\n",
        "// Vector size: 2^22\n",
        "// Number of Threads: 512\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "\n",
        "// Initialize data in CUDA kernel\n",
        "__global__\n",
        "void init(int n, float *out, float *in) {\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < n; i += stride) {\n",
        "    in[i] = float(i);\n",
        "    out[i] = float(0);\n",
        "  }\n",
        "}\n",
        "\n",
        "// 1-Dimensional convolution\n",
        "__global__\n",
        "void conv_1d(int n, float *out, float *in) {\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < n - 2; i += stride) {\n",
        "    out[i] = (in[i] + in[i+1] + in[i+2]) / 3.0f;\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "int main() {\n",
        "  // Initialize specs for program\n",
        "  const unsigned int RUNS = 30;\n",
        "  const unsigned int VECTOR_SIZE = 1 << 22;\n",
        "  const unsigned int THREAD_NUM = 512;\n",
        "  const unsigned int VECTOR_BYTES = VECTOR_SIZE * sizeof(float);\n",
        "  int numBlocks = (VECTOR_SIZE + THREAD_NUM - 1) / THREAD_NUM;\n",
        "\n",
        "  printf(\"\\n%s\\n\\n%s\\n%s: %u\\n%s: %d\\n%s: %d\\n\\n\",\n",
        "    \"#=== GPU-CPU Memory Transfer ===#\",\n",
        "    \"-- 1-D Convolution --\",\n",
        "    \"Vector size\", VECTOR_SIZE,\n",
        "    \"Number of threads\", THREAD_NUM,\n",
        "    \"Number of blocks\", numBlocks\n",
        "  );\n",
        "\n",
        "  // Allocate memory\n",
        "  float *in, *out;\n",
        "  cudaMallocManaged(&in, VECTOR_BYTES);\n",
        "  cudaMallocManaged(&out, VECTOR_BYTES);\n",
        "\n",
        "  // Initialize data in CUDA kernel\n",
        "  init<<<numBlocks, THREAD_NUM>>>(VECTOR_SIZE, out, in);\n",
        "\n",
        "  // Run kernel for 1-D convolution\n",
        "  for(int i = 0; i < RUNS; i++)\n",
        "    conv_1d<<<numBlocks, THREAD_NUM>>>(VECTOR_SIZE, out, in);\n",
        "\n",
        "  // Wait for GPU to finish before accessing on host\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  // Check for errors\n",
        "  int errorCount = 0;\n",
        "  unsigned int max = VECTOR_SIZE - 2;\n",
        "  for(int i = 0; i < max; i++) {\n",
        "    if((in[i] + in[i+1] + in[i+2]) / 3.0f != out[i])\n",
        "      errorCount++;\n",
        "  }\n",
        "  printf(\"Error count: %d\\n\", errorCount);\n",
        "\n",
        "  // Free memory\n",
        "  cudaFree(in);\n",
        "  cudaFree(out);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "t19Y6aNRabM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc cuda_4_2r22_512.cu -o cuda_4_2r22_512"
      ],
      "metadata": {
        "id": "t_JDHBEV3a6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvprof ./cuda_4_2r22_512"
      ],
      "metadata": {
        "id": "E0br7R283a6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of Threads: `1024`"
      ],
      "metadata": {
        "id": "aW3jfLY8abM6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cuda_4_2r22_1024.cu\n",
        "// Data Transfer method: Initialization as a CUDA Kernel\n",
        "// Vector size: 2^22\n",
        "// Number of Threads: 1024\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "\n",
        "// Initialize data in CUDA kernel\n",
        "__global__\n",
        "void init(int n, float *out, float *in) {\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < n; i += stride) {\n",
        "    in[i] = float(i);\n",
        "    out[i] = float(0);\n",
        "  }\n",
        "}\n",
        "\n",
        "// 1-Dimensional convolution\n",
        "__global__\n",
        "void conv_1d(int n, float *out, float *in) {\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < n - 2; i += stride) {\n",
        "    out[i] = (in[i] + in[i+1] + in[i+2]) / 3.0f;\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "int main() {\n",
        "  // Initialize specs for program\n",
        "  const unsigned int RUNS = 30;\n",
        "  const unsigned int VECTOR_SIZE = 1 << 22;\n",
        "  const unsigned int THREAD_NUM = 1024;\n",
        "  const unsigned int VECTOR_BYTES = VECTOR_SIZE * sizeof(float);\n",
        "  int numBlocks = (VECTOR_SIZE + THREAD_NUM - 1) / THREAD_NUM;\n",
        "\n",
        "  printf(\"\\n%s\\n\\n%s\\n%s: %u\\n%s: %d\\n%s: %d\\n\\n\",\n",
        "    \"#=== GPU-CPU Memory Transfer ===#\",\n",
        "    \"-- 1-D Convolution --\",\n",
        "    \"Vector size\", VECTOR_SIZE,\n",
        "    \"Number of threads\", THREAD_NUM,\n",
        "    \"Number of blocks\", numBlocks\n",
        "  );\n",
        "\n",
        "  // Allocate memory\n",
        "  float *in, *out;\n",
        "  cudaMallocManaged(&in, VECTOR_BYTES);\n",
        "  cudaMallocManaged(&out, VECTOR_BYTES);\n",
        "\n",
        "  // Initialize data in CUDA kernel\n",
        "  init<<<numBlocks, THREAD_NUM>>>(VECTOR_SIZE, out, in);\n",
        "\n",
        "  // Run kernel for 1-D convolution\n",
        "  for(int i = 0; i < RUNS; i++)\n",
        "    conv_1d<<<numBlocks, THREAD_NUM>>>(VECTOR_SIZE, out, in);\n",
        "\n",
        "  // Wait for GPU to finish before accessing on host\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  // Check for errors\n",
        "  int errorCount = 0;\n",
        "  unsigned int max = VECTOR_SIZE - 2;\n",
        "  for(int i = 0; i < max; i++) {\n",
        "    if((in[i] + in[i+1] + in[i+2]) / 3.0f != out[i])\n",
        "      errorCount++;\n",
        "  }\n",
        "  printf(\"Error count: %d\\n\", errorCount);\n",
        "\n",
        "  // Free memory\n",
        "  cudaFree(in);\n",
        "  cudaFree(out);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "_-gOjYw4abM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc cuda_4_2r22_1024.cu -o cuda_4_2r22_1024"
      ],
      "metadata": {
        "id": "Ha2wn_PG3k2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvprof ./cuda_4_2r22_1024"
      ],
      "metadata": {
        "id": "va2ejLh23k3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector Size: `2^24`"
      ],
      "metadata": {
        "id": "34UW0iUhadfO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of Threads: `256`"
      ],
      "metadata": {
        "id": "0r9BtTyGadfV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAYFYQseadfV"
      },
      "outputs": [],
      "source": [
        "%%writefile cuda_4_2r24_256.cu\n",
        "// Data Transfer method: Initialization as a CUDA Kernel\n",
        "// Vector size: 2^24\n",
        "// Number of Threads: 256\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "\n",
        "// Initialize data in CUDA kernel\n",
        "__global__\n",
        "void init(int n, float *out, float *in) {\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < n; i += stride) {\n",
        "    in[i] = float(i);\n",
        "    out[i] = float(0);\n",
        "  }\n",
        "}\n",
        "\n",
        "// 1-Dimensional convolution\n",
        "__global__\n",
        "void conv_1d(int n, float *out, float *in) {\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < n - 2; i += stride) {\n",
        "    out[i] = (in[i] + in[i+1] + in[i+2]) / 3.0f;\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "int main() {\n",
        "  // Initialize specs for program\n",
        "  const unsigned int RUNS = 30;\n",
        "  const unsigned int VECTOR_SIZE = 1 << 24;\n",
        "  const unsigned int THREAD_NUM = 256;\n",
        "  const unsigned int VECTOR_BYTES = VECTOR_SIZE * sizeof(float);\n",
        "  int numBlocks = (VECTOR_SIZE + THREAD_NUM - 1) / THREAD_NUM;\n",
        "\n",
        "  printf(\"\\n%s\\n\\n%s\\n%s: %u\\n%s: %d\\n%s: %d\\n\\n\",\n",
        "    \"#=== GPU-CPU Memory Transfer ===#\",\n",
        "    \"-- 1-D Convolution --\",\n",
        "    \"Vector size\", VECTOR_SIZE,\n",
        "    \"Number of threads\", THREAD_NUM,\n",
        "    \"Number of blocks\", numBlocks\n",
        "  );\n",
        "\n",
        "  // Allocate memory\n",
        "  float *in, *out;\n",
        "  cudaMallocManaged(&in, VECTOR_BYTES);\n",
        "  cudaMallocManaged(&out, VECTOR_BYTES);\n",
        "\n",
        "  // Initialize data in CUDA kernel\n",
        "  init<<<numBlocks, THREAD_NUM>>>(VECTOR_SIZE, out, in);\n",
        "\n",
        "  // Run kernel for 1-D convolution\n",
        "  for(int i = 0; i < RUNS; i++)\n",
        "    conv_1d<<<numBlocks, THREAD_NUM>>>(VECTOR_SIZE, out, in);\n",
        "\n",
        "  // Wait for GPU to finish before accessing on host\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  // Check for errors\n",
        "  int errorCount = 0;\n",
        "  unsigned int max = VECTOR_SIZE - 2;\n",
        "  for(int i = 0; i < max; i++) {\n",
        "    if((in[i] + in[i+1] + in[i+2]) / 3.0f != out[i])\n",
        "      errorCount++;\n",
        "  }\n",
        "  printf(\"Error count: %d\\n\", errorCount);\n",
        "\n",
        "  // Free memory\n",
        "  cudaFree(in);\n",
        "  cudaFree(out);\n",
        "\n",
        "  return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc cuda_4_2r24_256.cu -o cuda_4_2r24_256"
      ],
      "metadata": {
        "id": "uOHFTo5o31du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvprof ./cuda_4_2r24_256"
      ],
      "metadata": {
        "id": "vHgCycUs31d1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of Threads: `512`"
      ],
      "metadata": {
        "id": "y7CPW6IgadfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cuda_4_2r24_512.cu\n",
        "// Data Transfer method: Initialization as a CUDA Kernel\n",
        "// Vector size: 2^24\n",
        "// Number of Threads: 512\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "\n",
        "// Initialize data in CUDA kernel\n",
        "__global__\n",
        "void init(int n, float *out, float *in) {\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < n; i += stride) {\n",
        "    in[i] = float(i);\n",
        "    out[i] = float(0);\n",
        "  }\n",
        "}\n",
        "\n",
        "// 1-Dimensional convolution\n",
        "__global__\n",
        "void conv_1d(int n, float *out, float *in) {\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < n - 2; i += stride) {\n",
        "    out[i] = (in[i] + in[i+1] + in[i+2]) / 3.0f;\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "int main() {\n",
        "  // Initialize specs for program\n",
        "  const unsigned int RUNS = 30;\n",
        "  const unsigned int VECTOR_SIZE = 1 << 24;\n",
        "  const unsigned int THREAD_NUM = 512;\n",
        "  const unsigned int VECTOR_BYTES = VECTOR_SIZE * sizeof(float);\n",
        "  int numBlocks = (VECTOR_SIZE + THREAD_NUM - 1) / THREAD_NUM;\n",
        "\n",
        "  printf(\"\\n%s\\n\\n%s\\n%s: %u\\n%s: %d\\n%s: %d\\n\\n\",\n",
        "    \"#=== GPU-CPU Memory Transfer ===#\",\n",
        "    \"-- 1-D Convolution --\",\n",
        "    \"Vector size\", VECTOR_SIZE,\n",
        "    \"Number of threads\", THREAD_NUM,\n",
        "    \"Number of blocks\", numBlocks\n",
        "  );\n",
        "\n",
        "  // Allocate memory\n",
        "  float *in, *out;\n",
        "  cudaMallocManaged(&in, VECTOR_BYTES);\n",
        "  cudaMallocManaged(&out, VECTOR_BYTES);\n",
        "\n",
        "  // Initialize data in CUDA kernel\n",
        "  init<<<numBlocks, THREAD_NUM>>>(VECTOR_SIZE, out, in);\n",
        "\n",
        "  // Run kernel for 1-D convolution\n",
        "  for(int i = 0; i < RUNS; i++)\n",
        "    conv_1d<<<numBlocks, THREAD_NUM>>>(VECTOR_SIZE, out, in);\n",
        "\n",
        "  // Wait for GPU to finish before accessing on host\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  // Check for errors\n",
        "  int errorCount = 0;\n",
        "  unsigned int max = VECTOR_SIZE - 2;\n",
        "  for(int i = 0; i < max; i++) {\n",
        "    if((in[i] + in[i+1] + in[i+2]) / 3.0f != out[i])\n",
        "      errorCount++;\n",
        "  }\n",
        "  printf(\"Error count: %d\\n\", errorCount);\n",
        "\n",
        "  // Free memory\n",
        "  cudaFree(in);\n",
        "  cudaFree(out);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "PDM7mmNcadfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc cuda_4_2r24_512.cu -o cuda_4_2r24_512"
      ],
      "metadata": {
        "id": "RFVCpFAS4B4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvprof ./cuda_4_2r24_512"
      ],
      "metadata": {
        "id": "t31vztJN4B44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of Threads: `1024`"
      ],
      "metadata": {
        "id": "vYEhhKvTadfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cuda_4_2r24_1024.cu\n",
        "// Data Transfer method: Initialization as a CUDA Kernel\n",
        "// Vector size: 2^24\n",
        "// Number of Threads: 1024\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "\n",
        "// Initialize data in CUDA kernel\n",
        "__global__\n",
        "void init(int n, float *out, float *in) {\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < n; i += stride) {\n",
        "    in[i] = float(i);\n",
        "    out[i] = float(0);\n",
        "  }\n",
        "}\n",
        "\n",
        "// 1-Dimensional convolution\n",
        "__global__\n",
        "void conv_1d(int n, float *out, float *in) {\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < n - 2; i += stride) {\n",
        "    out[i] = (in[i] + in[i+1] + in[i+2]) / 3.0f;\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "int main() {\n",
        "  // Initialize specs for program\n",
        "  const unsigned int RUNS = 30;\n",
        "  const unsigned int VECTOR_SIZE = 1 << 24;\n",
        "  const unsigned int THREAD_NUM = 1024;\n",
        "  const unsigned int VECTOR_BYTES = VECTOR_SIZE * sizeof(float);\n",
        "  int numBlocks = (VECTOR_SIZE + THREAD_NUM - 1) / THREAD_NUM;\n",
        "\n",
        "  printf(\"\\n%s\\n\\n%s\\n%s: %u\\n%s: %d\\n%s: %d\\n\\n\",\n",
        "    \"#=== GPU-CPU Memory Transfer ===#\",\n",
        "    \"-- 1-D Convolution --\",\n",
        "    \"Vector size\", VECTOR_SIZE,\n",
        "    \"Number of threads\", THREAD_NUM,\n",
        "    \"Number of blocks\", numBlocks\n",
        "  );\n",
        "\n",
        "  // Allocate memory\n",
        "  float *in, *out;\n",
        "  cudaMallocManaged(&in, VECTOR_BYTES);\n",
        "  cudaMallocManaged(&out, VECTOR_BYTES);\n",
        "\n",
        "  // Initialize data in CUDA kernel\n",
        "  init<<<numBlocks, THREAD_NUM>>>(VECTOR_SIZE, out, in);\n",
        "\n",
        "  // Run kernel for 1-D convolution\n",
        "  for(int i = 0; i < RUNS; i++)\n",
        "    conv_1d<<<numBlocks, THREAD_NUM>>>(VECTOR_SIZE, out, in);\n",
        "\n",
        "  // Wait for GPU to finish before accessing on host\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  // Check for errors\n",
        "  int errorCount = 0;\n",
        "  unsigned int max = VECTOR_SIZE - 2;\n",
        "  for(int i = 0; i < max; i++) {\n",
        "    if((in[i] + in[i+1] + in[i+2]) / 3.0f != out[i])\n",
        "      errorCount++;\n",
        "  }\n",
        "  printf(\"Error count: %d\\n\", errorCount);\n",
        "\n",
        "  // Free memory\n",
        "  cudaFree(in);\n",
        "  cudaFree(out);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "YhQfGmLTadfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc cuda_4_2r24_1024.cu -o cuda_4_2r24_1024"
      ],
      "metadata": {
        "id": "62VZ-Dns4Qnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvprof ./cuda_4_2r24_1024"
      ],
      "metadata": {
        "id": "ch_699M24Qn7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}